---
title             : "Subclinical OCD and inference about absence in visual search"
shorttitle        : "Subclinical OCD visual search "

author: 
  - name          : "Noam Sarna"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Tel Aviv, Israel 69978"
    email         : "noamsarna@mail.tau.ac.il"

  - name          : "Ruvi Dar"
    affiliation   : "1"

  - name          : "Matan Mazor"
    affiliation   : "2"


affiliation:
  - id            : "1"
    institution   : "School of Psychological Sciences, Tel Aviv University"
  - id            : "2"
    institution   : "Department of Psychological Sciences, Birkbeck, University of London, UK"

abstract: |
   In previous research, obsessive-compulsive (OC) tendencies were associated with longer search times in a visual search setting. These findings, which were replicated and extended to a clinical sample, were specific to target-absent trials, with no effect on search times when a target was present in the display. Initially, this selectivity was interpreted as indicative of checking behavior in response to mild uncertainty. However, an alternative interpretation is that individuals with high OC tendencies (OC+) suffer from a more specific difficulty with inferences about absence. In two large-scale pre-registered online experiments (conceptual replication N = 1004, direct replication N = 226), we sought to replicate the original finding and shed further light on its underlying cause: an increased sensitivity to mild uncertainty, or a selective deficiency in inference about absence.  In both experiments, we find no evidence of prolonged search times in target-absent trials for OC+ individuals. Taken together, our findings provide no support for the previously observed higher search times of OC+ participants in target-absent trials. We discuss potential differences relative to previous findings and implications for cognitive and metacognitive theories of OCD.


bibliography      : "r-references.bib"

floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_word
---

```{r setup, include = FALSE}
library(papaja)
library(tidyverse)
library(reshape2)
library(wesanderson)
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

<!-- # Introduction  -->

In Experiment 1, target-absent search times were not significantly slower in OC+ compared to OC- individuals. While this stands in contrast to previous reports [@toffolo2013mild,@toffolo2014uncertainty, @toffolo2016patients], our experiment differed from the original study in several respects. Most notably, search times in this study (~4.5s for target-absent and ~2.6s for target-present) were shorter compared to those in @toffolo2013mild (~5.5 for target-absent and ~3.5s for target-present). Accordingly, we considered the possibility that the task used in experiment 1 may have been less challenging and potentially insufficient to elicit doubt and trigger repetitive checking behavior. In order to directly investigate this hypothesis, experiment 2 employed the original stimuli from @toffolo2013mild within an online sample to ascertain whether the failure to reproduce the effect resulted from an excessively easy task.



```{r Exp2_load_data, echo=FALSE, cache=TRUE}

# Pre processing  ---------------------------------------------------------

#load df from jatos 
exp2.jatos_df <-read_csv("../data/Exp_2_anon_jatos_results_10July2023.csv")


failed_practice <- exp2.jatos_df %>% 
  filter(trial_index != "trial_index") %>%
  group_by(subj_id) %>% 
  summarise(max_trail = max(as.double(trial_index, na.rm = T)),
            failed_practice = max_trail <= 42) %>% 
  select(subj_id, max_trail,failed_practice)  

exp2.jatos_df <- left_join(exp2.jatos_df, failed_practice)

n_failed_practice <- failed_practice %>% pull(failed_practice) %>% sum()

total_valid_n <- exp2.jatos_df %>%
  filter(failed_practice=='FALSE') %>%
  pull(subj_id) %>%  n_distinct()


#load prolific df 
exp2.demo_prolific<-read.csv("../data/Ex2_anon_demo_prolific.csv")
exp2.demo_prolific$subj_id <- as.factor(exp2.demo_prolific$subj_id)

#merge df
exp2.jatos_df$subj_id <- as.factor(exp2.jatos_df$subj_id)
exp2.jatos_df <- left_join(exp2.jatos_df, exp2.demo_prolific, by='subj_id')


#parse oci data from df 
exp2.OCI_df <- exp2.jatos_df %>%
  filter(failed_practice=='FALSE') %>% 
  filter(grepl('oci', Identifier)) %>% 
  select(subj_id, question, answer_oci) %>% 
  mutate(attention_check = question %in% c("OCI-Attention_check_1","OCI-Attention_check_2")) %>%
  arrange(subj_id, question)%>%
  #arrange it in a long format df 
  group_by(subj_id) %>%
  summarise(oci_overall=sum(as.numeric(answer_oci[!attention_check])), #compute oci general score 
            failed_attention_OCI = answer_oci[question=='OCI-Attention_check_1']!=0 | #attention check failure
              answer_oci[question=='OCI-Attention_check_2']!=2,
            OCI_Absent = answer_oci[question=='OCI-Absent']) %>%
  mutate(
    #split to quartiles based on toffolo 2013 scores 
    OCI_quantile = case_when(oci_overall>=17 ~ "high", 
                             oci_overall<=5 ~ "low",
                             TRUE ~ 'else'))

#count how many participants in each group 
exp2.OCI_df %>% group_by(OCI_quantile) %>% count()


# merge data with oci 
exp2.jatos_df <- left_join(exp2.jatos_df, 
                      exp2.OCI_df %>% select(subj_id, oci_overall, OCI_quantile, OCI_Absent),
                      by='subj_id')

############ create a df for the checking task 

exp2.checking_task <- exp2.jatos_df %>% 
  filter(trial_type == "image-keyboard-response") %>%
  filter(isPractice=='FALSE') %>% 
  select(trial_type,trial_index,subj_id,condition,
         rt,correct, isPractice, OCI_quantile, oci_overall, OCI_Absent)

#create a table making sure every participant have 50 trials, 25 absent and 25 present 
checking_table <-exp2.checking_task %>% group_by(subj_id) %>% 
  count(condition)

#recode variable
exp2.checking_task$rt <-as.numeric(exp2.checking_task$rt)

# accuracy df  -----------------------------------------------------------
exp2.checking_task$correct <- exp2.checking_task$correct=='TRUE' #change to Boolean 

exp2.checking_task <- exp2.checking_task %>% group_by(subj_id) %>% 
  mutate(mean_acc = mean(correct)) #calculate mean accuracy per subject 

#create accuracy df with acc score and OCI group per subject 
acc_data_frame <- exp2.checking_task %>% 
  group_by(subj_id) %>% select(subj_id, mean_acc, OCI_quantile) %>% slice(1)

#Create variables of accuracy in standard deviation units to exclude participants 
acc_data_frame$Zscore <-scale(acc_data_frame$mean_acc)[,1]

#take a look on overall accuracy scores 
acc_data_frame %>% 
  group_by(OCI_quantile) %>% 
  summarise(mean_acc=mean(mean_acc))

#Sanity check - standardized values should have: mean=0 and SD=1.  
round(mean(acc_data_frame$Zscore), 2)
round(sd(acc_data_frame$Zscore), 2)

#mark participant who had error greater than Z>-2.5
acc_data_frame$remove <-acc_data_frame$Zscore<(-2.5)

#merge acc df with the checking df 
exp2.checking_task <- left_join(exp2.checking_task, acc_data_frame)

#remove participants who had more than Z>-2.5 errors. Three participants are removed. 
exp2.checking_task <-exp2.checking_task %>%
  filter(remove=='FALSE')

 checking_by_sub <- exp2.checking_task %>% 
  filter(OCI_quantile!='else') %>% 
  group_by(subj_id, condition, OCI_quantile,
           oci_overall) %>%
  summarise(N = n(),
            mean_RT = mean(rt, na.rm = T),
            median_RT = median(rt, na.rm = T),
            sd_RT = sd(rt, na.rm = T)) %>% ungroup() %>%
  mutate(log_mRT = log(mean_RT)) %>% 
  mutate(oci_type = ifelse(.$OCI_quantile == 'high', "High OC (OC+)", "Low OC (OC-)")) %>% 
  mutate(target_present = ifelse(.$condition=='ABS', "Absent", "Present"))


```


# Methods
We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Participants
The research complied with all relevant ethical regulations and was approved by the Research Ethics Committee of Tel-Aviv University (study ID number 0004169-1). Two hundred twenty-six participants were recruited via Prolific. We invited former participants whose OCI scores were in the top or bottom OCI quantile in Exp. 1. In line with our preregistered stopping rule, we kept data collection until we had invited all participants in the first and fourth quartiles from our previous experiment (n=250; n=239, respectively). Participants completed the OCI questionnaire in this second session to.  We then split the sample into OC+/OC- groups based on cut-off scores from @toffolo2013mild (OCI-R total score ≥ 17 for the OC+ group; OCI-R total score ≤ 5 for the OC- group). Our final sample consisted of 110 OC+ participants and 68 OC- participants. The entire experiment took 12 minutes to complete, and participants were paid £1.8 for their participation, equivalent to an hourly wage of £9.

## Material
We used the original stimuli used in @toffolo2013mild, as provided by the authors. The visual search task consisted of one block of 50 individual search displays, each containing 25 elements. Half of the search displays were target-absent trials, in which 25 squares with a gap in one of the four edges were presented, and the other half were target-present trials, in which 24 open squares were presented and one closed square, the target. To make sure participants understood the task, a practice phase was given first. The practice phase consisted of 4 search displays, (2 target-absent and 2 target-present). In the practice phase, participants got feedback on their response accuracy. Participants were able to move to the next part of the experiment only after getting all questions right (4/4). The practice phase repeated until the performance was perfect, or until it has repeated more than three times, at which point the experiment terminated. Each trial lasted for a maximum of 10 seconds or until a response was received. If no response was given within 10 seconds, the next trial immediately appeared. Feedback about the response was given only in the practice phase, to help participants learn the task efficiently. In the main part of the experiment, no feedback was given.

## Procedure
A static version of experiment 2 can be accessed here: jatos.mindprobe.eu/publix/Qkm6hi2c3vS.  Experiment 2 was similar to experiment 1 with the following exceptions. First, the search task was more challenging due to an enlarged search grid, which led to larger gaps between stimuli, as well as reduced stimulus size and narrower sides of the squares. Second, experiment 2 did not had a perceived difficulty estimation part and was comprised of two parts: a visual search part and study questionnaires. Third, to make it identical to @toffolo2013mild, the practice trials in experiment 2 involved the same stimuli as the main blocks. Forth, participants were instructed to press the spacebar key to move to the search display screen. Once they pressed the space bar, the search display appeared immediately . Finally, the main part of the experiment included only the hard search type: looking for a closed square among open squares. 

The preregistered analysis plan can be accessed at the following link: https://osf.io/8a5mr. As in Experiment 1, we employed the Mersenne Twister pseudorandom number generator to ensure that our preregistration preceded data collection @mazor2019novel. Since Experiment 2 served as a direct replication, we adopted the same rejection criteria as @toffolo2013mild, in which participants were excluded if their error count exceeded 2.5 standard deviations from the mean error rate of the entire sample. In line with Experiment 1, participants were also excluded from the analysis if they incorrectly answered one or more attention-check questions. 


###Randomization
The order and timing of experimental events will be determined pseudo-randomly by the Mersenne Twister pseudorandom number generator, initialized to ensure registration time-locking [@mazor2019novel].


## Data analysis
We used `r cite_r("r-references.bib")` for all our analyses.


# Results
```{r Exp2_analyze_data, echo=FALSE, cache=TRUE}

#plot figure of mean RT for each group  

checking_by_sub %>% 
select(subj_id, target_present, oci_type, mean_RT)  %>%
  ggplot(aes(x = target_present, y = mean_RT,  group = oci_type, shape = oci_type)) +
  stat_summary(fun = mean,
               geom = "point",
               position = position_dodge(0.9),
               size = 5) +
  stat_summary(fun.data = mean_se,
               geom = "errorbar",
               width = 0.4,
               position = position_dodge(0.9)) +
  # stat_summary(fun = mean,
  #              geom = "line",
  #              position = position_dodge(0.9)) +
  scale_shape_manual(values = c("High OC (OC+)" = 1, "Low OC (OC-)" = 2)) +
  scale_x_discrete(labels = c("FALSE" = "Absent", "TRUE" = "Present")) +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        text = element_text(size = 12)) +
  ylab('Mean RT (ms)')+
  labs(shape = "OC group")+ 
  coord_cartesian(ylim = c(2500,7500))

#ggsave(filename = "exp_2_results.png",width = 4, height = 3, dpi = 1500)  


# make a planned contrast df in which every participant has one raw with a difference score of the mean 
#target absent search time minus the mean target present search time. 

planned_df <- exp2.checking_task %>% 
  filter(rt!='null') %>%   filter(OCI_quantile!='else') %>% 
  group_by(subj_id, condition, OCI_quantile, oci_overall) %>% 
  summarise(mean_RT =mean(rt))%>% ungroup

#long to wide format 
planned_wide <- spread(planned_df, key = condition, value = mean_RT)

#adding difference score 
planned_wide <- planned_wide %>% mutate(RT_diff = ABS- PRE) 
#mean for target present trials - 
round(mean(unlist(planned_df[planned_df$condition=='PRE', 'mean_RT'])), 2)

#mean for target absent trials -
round(mean(unlist(planned_df[planned_df$condition=='ABS', 'mean_RT'])), 2)


Exp2_H1_desc <-planned_df %>% group_by(condition) %>% summarise(mean_rt=mean(mean_RT),
                                                                sd = sd(mean_RT))

```

*Hypothesis 1 - Task validation*  
To validate our paradigm and demonstrate that target-absent searches are more difficult, we tested for an effect of condition (target-absent vs. target-present) on mean search times, collapsed across both groups. Our results revealed the expected difference `r apa_print(t.test(mean_RT~condition, data=planned_df, alternative='greater', paired=T))$statistic` with `r printnum(Exp2_H1_desc[2 ,2])` `r printnum(Exp2_H1_desc[2 ,3])` for target-present responses and `r printnum(Exp2_H1_desc[1 ,2])` `r printnum(Exp2_H1_desc[1 ,3])` ms for target-absent responses. 


*Hypothesis 2 - Direct replication* 
The primary aim of experiment 2 was to examine the interaction between group (OC+ vs. OC-) and condition (target-absent vs. target-present). We conducted a one-tailed t-test using the difference in search times (mean RT absent - mean RT present) as the dependent variable and group (OC+ vs. OC-) as the independent variable, expecting a greater difference score for the OC+ group. The one-tailed t-test revealed no significant differences between the groups,`r apa_print(t.test(RT_diff~OCI_quantile, data=planned_wide, alternative="greater"))$statistic`, providing no evidence for the expected interaction.




# Discussion


\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
