---
title             : "Subclinical OCD and inference about absence in visual search"
shorttitle        : "Subclinical OCD visual search "

author: 
  - name          : "Noam Sarna"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Tel Aviv, Israel 69978"
    email         : "noamsarna@mail.tau.ac.il"

  - name          : "Ruvi Dar"
    affiliation   : "1"

  - name          : "Matan Mazor"
    affiliation   : "2"


affiliation:
  - id            : "1"
    institution   : "School of Psychological Sciences, Tel Aviv University"
  - id            : "2"
    institution   : "Department of Psychological Sciences, Birkbeck, University of London, UK"

abstract: |
  In previous research, obsessive-compulsive (OC) tendencies were associated with longer search times in a visual search setting. These findings, which were replicated and extended to a clinical sample, were specific to target-absent trials, with no effect on search times when a target was present in the display. Initially, this selectivity was interpreted as indicative of checking behavior in response to mild uncertainty. However, an alternative interpretation is that individuals with high OC tendencies (OC+) suffer from a more specific difficulty with inferences about absence. In two large-scale pre-registered online experiments (conceptual replication N = 1004, direct replication N = 226), we sought to replicate the original finding and shed further light on its underlying cause: an increased sensitivity to mild uncertainty, or a selective deficiency in inference about absence.  In both experiments, we find no evidence of prolonged search times in target-absent trials for OC+ individuals. Taken together, our findings provide no support for the previously observed higher search times of OC+ participants in target-absent trials. We discuss potential differences relative to previous findings and implications for cognitive and metacognitive theories of OCD. 

  
bibliography      : "r-references_full_paper.bib"

floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_word
---

```{r setup, include = FALSE, warning=FALSE}

library(tidyverse)
library(broom)
library(nlme)
library(lme4)
library(lmerTest)
library(ggpubr)
library(cowplot)
library(caret)
library(papaja)
library(lvmisc)
library(wesanderson)
library(patchwork)
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

<!-- # Introduction  -->

Theories on obsessive-compulsive disorder (OCD) emphasize the pivotal role of pathological doubt in the disorder's phenomenology [@rasmussenClinicalFeaturesPhenomenology1989; @reedObsessionalExperienceCompulsive1985a; @shapiroNeuroticStyles1965]. This persistent doubt, marked by increased uncertainty, gives rise to repetitive checking rituals that, paradoxically, serve to intensify the doubt itself. In laboratory perceptual studies, checking behavior is commonly manifested in slow reaction times, as OC participants require more evidence under high uncertainty [@bancaEvidenceAccumulationObsessiveCompulsive2015; @hauserMetacognitiveImpairmentsExtend2017d. Previous studies found that participants with high obsessive compulsive tendencies (OC+) take longer to decide that a target is absent from a visual search array compared to those with low obsessive compulsive tendencies (OC-; @toffoloMildUncertaintyPromotes2013). These finding have been replicated [@toffoloUncertaintyCheckingIntolerance2014] and extended to a clinical sample, where they were found to be specific to patients with OCD and absent in those suffering from anxiety [@toffoloPatientsObsessiveCompulsiveDisorder2016].  In these experiments, checking behavior was operationalized by search time, and high and low uncertainty were operationalized by means of contrasting target-present and target-absent trials. Therefore, relatively longer search times for the OC+ group in target-absent trials were interpreted as perseverative checking behavior under mild uncertainty. 


```{r load_data, echo=FALSE, cache=TRUE}

#load anon jatos data 
df<- read_csv('../data/anon_jatos_results_p1.csv')
df2<- read_csv('../data/anon_jatos_results_p2.csv')

df <- rbind(df, df2)
rm(df2)

#load anon prolific data 
demo_prolific <- read.csv('../data/anon_demo_prolific.csv')


# create OCI data ---------------------------------------------------------

#parse oci data from df 
OCI_df <- df %>%
  filter(grepl('oci', Identifier)) %>% 
  select(subj_id, question, answer_oci) %>% 
  mutate(attention_check = question %in% c("OCI-Attention_check_1","OCI-Attention_check_2")) %>%
  arrange(subj_id, question)%>%
  #arrange it in a long format df 
  group_by(subj_id) %>%
  summarise(oci_overall=sum(as.numeric(answer_oci[!attention_check])), #compute oci general score 
            failed_attention_OCI = answer_oci[question=='OCI-Attention_check_1']!=0 | #attention check failure
            answer_oci[question=='OCI-Attention_check_2']!=2,
            OCI_Absent = answer_oci[question=='OCI-Absent']) %>%
  mutate(
  #split to quartiles based on oci score
    OCI_quantile = as.numeric(cut(oci_overall,
                                  breaks = quantile(oci_overall[!failed_attention_OCI],
                                                    probs = seq(0, 1, 0.25),
                                                    na.rm = T,
                                                    type = 9),
                                  right = F, 
                                  include.lowest = T,
                                  include.highest = T))
  )

# create DASS data ---------------------------------------------------------

#create vectors for DASS subscales. 
DASS_anxiety <- c("DASS-4","DASS-7", "DASS-9", "DASS-15", "DASS-19", "DASS-20")
DASS_depression <- c("DASS-3","DASS-5", "DASS-10", "DASS-13", "DASS-16", "DASS-17","DASS-21")

#parse DASS data from df
DASS_df <- df %>%
  filter(grepl('DASS', Identifier)) %>% 
  select(subj_id, question, answer_dass) %>% 
  arrange(subj_id, question) %>%
  #arrange in a new df 
  group_by(subj_id)%>%
  summarise(DASS_anxiety = sum(as.numeric(answer_dass[question %in% DASS_anxiety])),
            DASS_depression = sum(as.numeric(answer_dass[question %in% DASS_depression])))

# unite dass and oci
questionnaires_df <- left_join(OCI_df, DASS_df,by = "subj_id")


# df of explicit difficulty rating---------------------------------------------------

#get data from df 
difficulty_rating <- df %>% 
  filter(trial_type == "html-slider-response") %>% 
  select(subj_id,test_part,response) %>%
  #retrieve variable names. 
  mutate(difficulty_rating = case_when(str_detect(test_part,"PresentOinC25") ~ "OinC_25_TP",
                                       str_detect(test_part,"Absent09") ~ "CinO_9_TA",
                                       str_detect(test_part,"PresentOinC09") ~ "OinC_9_TP",
                                       str_detect(test_part,"Absent25") ~ "CinO_25_TA")) %>% 
  select(-test_part) %>% 
  
  #adding OCI quantile to difficulty df 
  left_join(questionnaires_df %>% 
              group_by(subj_id) %>%
              summarise(OCI_quantile=first(OCI_quantile)) %>% 
              select(subj_id, OCI_quantile), 
            difficulty_rating,
            by = "subj_id")

# visual search df -------------------------------------------------------------

search_df <- df %>% 
  filter(trial_type == "p5vs_yn_small_grid") %>%
  select(trial_type,trial_index,subj_id,sequence,target_position,
          subj_id,set_size,target_present,
         RT,test_part,correct,search_type) %>% 
# unite search and questionnaire dfs together 
  left_join(questionnaires_df,
                       by = "subj_id") %>% 
  #unite search df with demo prolific 
  left_join(.,demo_prolific,
            by = "subj_id")

#recode variables 
search_df$target_present<-search_df$target_present=='TRUE'
search_df$RT <- as.numeric(search_df$RT)
search_df$correct <- as.numeric(as.logical(search_df$correct))
search_df$set_size <- as.factor(search_df$set_size)
 

# Rejecting participants with more than 15% error trials -----------------------

rejection_df <- search_df %>% 
  group_by(subj_id) %>% 
  summarise(accuracy = mean(correct)) %>% 
  mutate(reject = accuracy<0.85)

rejected_num <- sum(rejection_df$reject=='TRUE')


# flag bad trails
search_df <- search_df %>% rowwise() %>% 
  mutate(under_100 = as.numeric(RT <= 100)) 


#filter out participants for accuracy and attention check 
search_df <- left_join(search_df, 
                       rejection_df %>% select(subj_id, reject), 'subj_id') %>%
  # filter(reject=='FALSE' | failed_attention_OCI == 1)
  filter(reject=='FALSE' & failed_attention_OCI == 0) %>%
  filter(under_100 == 0) #filter our trials 

#total n after participants removal 
df.N_total <- search_df$subj_id %>% unique() %>% length()

#total n in each quartile 
#search_df %>% select(subj_id, OCI_quantile) %>% unique() %>% select(OCI_quantile) %>% table()

```

# Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Participants

The research complied with all relevant ethical regulations and was approved by the Research Ethics Committee of Tel-Aviv University (study ID number 0004169-1). Participants will be recruited via Prolific and selected based on their acceptance rate (>95%) and for being native English speakers, located in the UK, and not having participated in former study pilots. We encountered graphical problems with Safari browser during the pilot study, so we will ask participants to use only other browsers. The entire experiment will take 14 minutes to complete (the median completion time in a pilot study). Participants will be paid £2 for their participation, equivalent to an hourly wage of £8.57.

## Material

Visual search task The experiment described in this study was adapted from [@mazor2022efficient], with stimuli created to replicate the ones used in the [@toffolo2013mild] experiment. All elements (distractors and target) and their placement on the search grid were made to replicate as closely as possible the paradigm used in @toffolo2013mild. The visual search task will consist of 4 blocks, each containing 24 trials of searching for either a closed or an open square. To make sure participants understand the task, a practice phase will be given first. The practice phase will consist of one block with six trials of visual search. Elements in both practice and main part will be white on dark grey background. Each trial will last for a maximum of 10 seconds or until a response is received. If no response is given within 10 seconds, the next trial will immediately appear. Feedback about the response (wrong/right) will be given only in the practice phase, to help participants learn the task efficiently. In the main part of the experiment, no feedback will be given, as was the case in the original paradigm [@toffolo2013mild].

## Procedure

Participants will first be instructed about the experiment's structure, which comprises three parts: A visual search part, questions about the visual search part, and some more general questions. Then, they will be informed about the main part of the experiment -- the visual search part. Specifically, their task is to report, as accurately and quickly as possible, whether a target stimulus was present (press 'J') or absent (press 'F'). Then, practice trials will be delivered, in which the target stimulus is a rotated T, and distractors are rotated Ls. The purpose of the practice trials is to familiarize participants with the task structure. For these practice trials, the number of items will always be 4. In the practice trials, participants will be given feedback about the accuracy of their responses. The feedback will appear right after a response is given. If the response is correct, then the word "Correct!" will immediately pop on the screen, for 1 second. If the response is wrong, the word "Wrong!" will immediately pop on the screen for 5 seconds. The extended duration of the word "wrong" is intended to feel aversive and to make sure participants are paying full attention and giving accurate responses (a pilot study showed higher accuracy rates when using this method). Practice trials will be delivered in one block of 6 trials, and the main part of the experiment will start only once participants respond correctly on at least five trials.

We used `r cite_r("r-references.bib")` for all our analyses.


# Results

```{r analyze_data, echo=FALSE, cache=TRUE}

# Perceived difficulty pre-processing -------------------------------------

difficulty_rating_by_condition <- difficulty_rating %>% 
  mutate(condition=case_when(str_detect(difficulty_rating, "_TA") ~ "Absent",
                             str_detect(difficulty_rating, "_TP") ~ "Present")) %>% 
  group_by(difficulty_rating, condition) %>%
  summarise(mean = mean(as.numeric(response), na.rm = T),
            sd = sd(as.numeric(response), na.rm = T)) %>% 
  ungroup() 

#difficulty rating with oc quantile 
difficulty_rating_by_condition_with_oci <- difficulty_rating %>% 
  mutate(condition=case_when(str_detect(difficulty_rating, "_TA") ~ "Absent",
                             str_detect(difficulty_rating, "_TP") ~ "Present")) %>% 
  group_by(difficulty_rating, condition, OCI_quantile) %>%
  summarise(mean = mean(as.numeric(response), na.rm = T),
            sd = sd(as.numeric(response), na.rm = T)) %>% 
  ungroup() %>% 
  filter(OCI_quantile=='1' | OCI_quantile=='4') %>% 
  mutate(OCI_quantile_factor = recode(OCI_quantile, '1'='low', '4'='high'))

# Summary dfs  ------------------------------------------------------------

search_summary_RT <- 
  #every participant gets a median score for each search option (8)
  #we use median because we didn't exclude longer RT
  search_df %>% 
  filter(correct==1) %>% #only correct trials 
  group_by(subj_id, set_size,search_type, target_present, OCI_quantile) %>% 
  summarise(median_RT = median(RT, na.rm = T)) %>%
  ungroup() 

RT_over_participant <-
  search_summary_RT %>% group_by(set_size,search_type, target_present) %>%
  summarise(mean_RT= mean(median_RT, na.rm = T)) %>% 
  ungroup()


RT_over_participant_oci <-
  search_summary_RT %>% group_by(set_size,search_type, target_present, OCI_quantile) %>%
  summarise(mean_RT= mean(median_RT, na.rm = T)) %>% 
  ungroup()

toffolo_data <- search_df %>%
  filter(set_size == 25) %>% 
  filter(search_type == "OinC") %>% 
  arrange(subj_id, target_present)


by_sub_toffolo <- toffolo_data %>% 
  group_by(subj_id, target_present, OCI_quantile, 
           oci_overall,
           DASS_anxiety, DASS_depression, Age) %>% 
  summarise(N = n(),
            mean_RT = mean(RT, na.rm = T),
            median_RT = median(RT, na.rm = T),
            sd_RT = sd(RT, na.rm = T)) %>% ungroup() %>% 
  mutate(log_mRT = log(mean_RT))

# Extracting slopes ------------------------------------------------------------------

#Reordering set size to get the slopes for the effect of going from 9 to 25. 
search_df$set_size <- relevel(as.factor(search_df$set_size), '9')

#extracting slopes 
search_slopes_df <- search_df %>%
  group_by(subj_id,search_type,target_present) %>%
  nest() %>%
  mutate(model = map(data, ~ lm(RT ~ set_size, data =.)),
         tidy = map(model, ~ tidy(.x))) %>%
  unnest(tidy) %>%
  # we are interested in the slope, i.e., the effect of set size.
  filter(term=='set_size25')

search_slopes_df<- left_join(search_slopes_df, questionnaires_df %>% 
                               select(subj_id, OCI_quantile, oci_overall, DASS_depression, DASS_anxiety),
                             by='subj_id') 



slopes_table <-search_slopes_df %>% 
  group_by(OCI_quantile, search_type, target_present) %>% 
  summarise(mean(estimate)) %>%
  filter(OCI_quantile==1 | OCI_quantile==4)


```
```{r h1_h2_t-test, echo=FALSE, cache=TRUE}
#creating a df for second hypothesis testing 

H1.desc <- search_slopes_df %>% group_by(search_type) %>%  
  summarise(mean_slope = mean(estimate),
            ms_item = mean_slope/(25-9))

H2.df<- search_slopes_df %>% 
  filter(target_present==TRUE & search_type=='OinC' |target_present==FALSE & search_type=='CinO')  %>% 
  mutate(group = case_when(search_type == 'OinC' ~ 'hard_present',
                           search_type == 'CinO' ~ 'easy_absent'));
                          
H2.desc <- H2.df %>% 
  group_by(group) %>% 
  summarise(mean_slope=mean(estimate),
            ms_item = mean_slope/(25-9))

```

*Hypotheses 1 and 2 - Task validation * - To validate our paradigm structure and to assess whether we successfully created an easier search by leveraging search asymmetries (i.e., switching between the target and distractors), we first examined the difference in slopes between the two search types (easy/hard), regardless of target presence (pre-registered hypothesis H1). As anticipated, a one-tailed paired t-test demonstrated a steeper slope for the difficult search `r printnum (H1.desc[2,3])` ms/item compared to the easy search  `r printnum (H1.desc[1,3])` ms/item, `r apa_print(t.test(estimate~search_type, data=search_slopes_df, paired=T))$statistic`. Furthermore, a one-tailed paired t-test revealed that target-present slopes in the hard search `r printnum (H2.desc[2,3])` ms/item were steeper than target-absent slopes in the easy search `r printnum (H2.desc[1,3])` ms/item, `r apa_print(t.test(estimate~group, data=H2.df, paired=T))$statistic` (pre-registered hypothesis H2).


The initial two control comparisons served to validate that we successfully designed a target-absent condition that was easier than a target-present condition, thereby experimentally decoupling decision certainty from target presence, and enabling to measure their independent effects on search time as a function of obsessive-compulsive tendencies.


```{r DR_h3, echo=FALSE, cache=TRUE}
  
  # Toffolo replication plots -----------------------------------------------------


exp1_mean_RT_fig <- by_sub_toffolo%>% 
    filter(OCI_quantile == 1 | OCI_quantile == 4) %>% 
    mutate(oci_type = ifelse(.$OCI_quantile == 1, "Low OC (OC-)", "High OC (OC+)")) %>% 
    select(subj_id, target_present, oci_type, mean_RT)  %>%
    ggplot(aes(x = target_present, y = mean_RT,  group = oci_type, shape = oci_type)) +
    stat_summary(fun = mean,
                 geom = "point",
                 position = position_dodge(0.9),
                 size = 5) +
    stat_summary(fun.data = mean_se,
                 geom = "errorbar",
                 width = 0.4,
                 position = position_dodge(0.9)) +
    # stat_summary(fun = mean,
    #              geom = "line",
    #              position = position_dodge(0.9)) +
    scale_shape_manual(values = c("High OC (OC+)" = 1, "Low OC (OC-)" = 2)) +
    scale_x_discrete(labels = c("FALSE" = "Absent", "TRUE" = "Present")) +
    theme_bw() +
    theme(axis.title.x = element_blank(),
          text = element_text(size = 12)) +
    ylab('Mean RT (ms)')+
    labs(shape = "OC group")+ 
    coord_cartesian(ylim = c(2500,7500))
  
  
#ggsave(filename = "exp_1_results.png",width = 4, height = 3, dpi = 1500)  


H3.df <- toffolo_data %>% 
  filter(OCI_quantile==1| OCI_quantile==4) %>%
  group_by(subj_id, OCI_quantile, target_present) %>%
  summarise(mean_RT=mean(RT)) %>% 
  ungroup()

```

*Hypothesis 3 - Replication of Toffolo et al. (2013), mean RT*
To directly replicate the findings of Toffolo et al. (2013, 2014, 2016), we focused on the difficult search with the larger set size (set size = 25). We conducted a mixed-effects ANOVA, with mean response time (RT) as the dependent variable, group (OC+ vs. OC-) as a between-subjects variable, and target presence (present vs. absent) as a within-subjects variable. Specifically, we tested for an interaction between group and target presence, wherein the mean RT difference between the OC+ and OC- groups would be significantly larger in target-absent trials. Contrary to our expectations, the analysis did not reveal a significant interaction between group and target presence, `r apa_print(afex::aov_ez("subj_id", "mean_RT", H3.df, between = "OCI_quantile", within = "target_present"))$statistic$OCI_quantile_target_present`, suggesting no difference in mean RT between the OC+ and OC- groups in either target-present or target-absent trials (figure 3). 

```{r h4_anova, echo=FALSE, cache=TRUE}

H4.df<- search_slopes_df %>% 
  filter(OCI_quantile==1 | OCI_quantile==4) %>% 
  filter(search_type=='OinC')
                          
H4.desc <- H4.df %>% group_by(OCI_quantile, target_present) %>% summarise(mean_slope = mean(estimate))

```


*Hypothesis 4: Extension of Toffolo et al. (2013), search slopes*
Following the previous hypothesis, we conducted the same mixed-effects ANOVA, with group (OC+/OC-) as between-subject variable and target presence (present/absent) as within-subject variables, only this time, we focused on the search slopes (reaction time as a function of set size) as a dependent variable. Consistent with our findings for Hypothesis 3, a mixed-effects ANOVA revealed no statistically significant interaction between group and target presence `r apa_print(afex::aov_ez("subj_id", "estimate", data=H4.df, between = "OCI_quantile", within = "target_present"))$statistic$OCI_quantile_target_present`, again providing no evidence for a selective slowing of OC+ individuals in target-absent trials. 

```{r h5_anova, echo=FALSE, cache=TRUE}
H5.df <- search_slopes_df %>% filter(OCI_quantile==1| OCI_quantile==4) %>% filter(search_type=='CinO')

```

*Hypothesis 5: Low-uncertainty inference about absence*  
Originally, our primary focus was on this hypothesis, examining the effect of obsessive-compulsive tendencies on target-absent search times in an easy, low-uncertainty, search setting. However, given our failure to replicate a group difference in the hard search (Hypotheses 3 and 4), a significant result here seemed unlikely. Indeed, a mixed-effects ANOVA with group as a between-subjects variable and target presence as a within-subjects variable did not reveal a significant interaction between group and target presence in the easy search, `r apa_print(afex::aov_ez("subj_id", "estimate", H5.df, between = "OCI_quantile", within = "target_present"))$statistic$OCI_quantile_target_present`. 


```{r model_comparison, echo=FALSE, cache=TRUE}

#We didn't use LOOCV since we included random terms in our model. So instead we comapred models by their AIC and BIC values.  

m1 <- 
  search_slopes_df%>% 
  filter(OCI_quantile==1|OCI_quantile==4) %>% 
  mutate(OCI_group = recode(OCI_quantile, '1'='low', '4'='high')) %>% 
  
  lmer(estimate ~ 1+OCI_group+ search_type * target_present +search_type *OCI_group+
         (search_type+target_present|subj_id), #random slope for search type and target present for each participant 
        data =.)

#examine model parameters 
#parameters::model_parameters(m1)

#second model 
#fit a regression model with random intercept for participant 

m2 <- 
  search_slopes_df%>% 
  filter(OCI_quantile==1|OCI_quantile==4) %>% 
  mutate(OCI_group = recode(OCI_quantile, '1'='low', '4'='high')) %>% 
  
  lmer(estimate ~ 1+OCI_group+ search_type * target_present +target_present *OCI_group+
         (search_type+target_present|subj_id),
        data = .)

#examine model parameters 
#parameters::model_parameters(m2)


H6.model_acc_table <-as.data.frame(compare_accuracy(m1, m2))  %>% 
  select(Model, AIC, BIC)

H6.model_acc_table

#I had problem creating this table in APA format and also including the formula within the table.. Would appreciate some help with that.  

```
*Hypothesis 6: Model comparison*
Our experimental design aimed to differentiate between difficulties arising from higher uncertainty and those arising from the absence of the target. To achieve this, we used two search types: a hard search (searching for a closed square among open squares), and an easy search (searching for an open square among closed squares). Additionally, we manipulated the presence or absence of the target. To determine whether uncertainty or absence had a greater impact on OC+ search time, we constructed two competing regression models that differed only in their interaction terms (table 1). Beyond the search type and the target presence predictors, the first model (M1) included the interaction between group and search type (easy/hard; slope_estimate~ 1+group+search_type * target_presence+ search_type * group), while the second model (M2) included the interaction between group and target presence (absent/present; slope_estimate~ 1+group+ search_type * target_present+target_present * group). 
Since the two models differ only in their last interaction effect, their complexity (that is, the number of fitted coefficients) is the same, which allowed us to compare these models directly. We compare model performance using their AIC and BIC values. The model comparison table shows that both models have the same AIC and BIC values suggesting that the interaction between group and target presence does not explain search time to a greater extent than the interaction between group and search type.




# Discussion

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
