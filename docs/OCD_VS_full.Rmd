---
title: "Obsessive Compulsive visual search: a reexamination of presence-absence asymmetries"
shorttitle: "Obsessive Compulsive visual search: a reexamination of presence-absence asymmetries"

author: 
  - name: "Noam Sarna"
    affiliation: "1"
    corresponding: yes    # Define only one corresponding author
    address: "Tel Aviv, Israel 69978"
    email: "noamsarna@mail.tau.ac.il"
    
  - name: "Matan Mazor"
    affiliation: "2"

  - name: "Ruvi Dar"
    affiliation: "1"

affiliation:
  - id: "1"
    institution: "School of Psychological Sciences, Tel Aviv University"
  - id: "2"
    institution: "Department of Experimental Psychology, University of Oxford"

abstract: |
  In previous research, obsessive-compulsive (OCD) tendencies were associated with longer search times in visual search task. These findings, replicated and extended to a clinical sample, were specific to target-absent trials, with no effect on target-present trials. This selectivity was interpreted as checking behavior in response to mild uncertainty. However, an alternative interpretation is that individuals with high OCD tendencies (OC+) have a specific difficulty with inference about absence. In two large-scale pre-registered online experiments (conceptual replication N= 1007; direct replication N= 226), we sought to replicate the original finding and elucidate its underlying cause: an increased sensitivity to mild uncertainty, or a selective deficiency in inference about absence. Both experiments showed no evidence of prolonged search times in target-absent trials for OC+ individuals. Taken together, our results do not support the notion that inducing mild uncertainty in the form of target absence leads to excessive checking among OC+ individuals.
  
bibliography: "r-references.bib"

floatsintext: no
linenumbers: yes
draft: no
mask: no

figurelist: no
tablelist: no
footnotelist: no

classoption: "man"
output: papaja::apa6_word
appendix: appendix.rmd
---

```{r setup, include = FALSE, warning=FALSE}

library('groundhog')
groundhog.library(c(
  "tidyverse",
  "broom",
  "lmerTest",
  "ggpubr",
  "cowplot",
  "papaja",
  "patchwork",
  "wesanderson",
  "reshape2", 
  "rlang",
  "Matrix",
  "lvmisc",
  "rstatix", #for Cohen's d 
  "BayesFactor",
  "moments", #compute skewness and Kurtosis 
  "ltm" #compute alpha cronbach 
),"2023-09-01", ignore.deps = c('knitr', 'xfun'), 
force.install=TRUE)
#, tolerate.R.version = '4.1.2')
```

```{r analysis-preferences}
 # Seed for random number generation
 set.seed(42)
 knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Introduction

Theories on obsessive-compulsive disorder (OCD) emphasize the pivotal role of pathological doubt in the disorder's phenomenology [@dar2004; @darSeekingProxies2021; @rasmussen1989; @reed1985] This persistent doubt is reflected in lowered confidence in memory, decision-making, perception and other cognitive functions, which give rise to repetitive checking rituals that, paradoxically, only serve to intensify the doubt [@vandenhout2003]. In the lab, doubt and checking behavior are commonly manifested in slow reaction times (e.g., @sarig2012; @banca2015; @hauser2017.

The present study focused on the finding that participants with high OCD tendencies (OC+) took more time than those with low OCD tendencies (OC-) to identify when a target was absent from a visual search array, whereas no such difference was observed when the target was present [@toffolo2013]. These findings have been replicated [@toffolo2014] and extended to a clinical sample, where they were found to be specific to patients with OCD and absent in those suffering from anxiety [@toffolo2016]. In these experiments, checking behavior was operationalized as search time, and high and low uncertainty were operationalized by means of contrasting target-present and target-absent trials. Relatively longer search times for the OC+ group in target-absent trials were interpreted as perseverative checking behavior under mild uncertainty. However, while deciding that a target is absent is indeed commonly accompanied by lower levels of subjective confidence compared to deciding that a target is present [@mazorDistinctNeuralContributions2020; @mazorRegisteredReport2021], these type of decisions about absence, are also qualitatively different from decisions about presence, as they cannot be based on direct perceptual evidence. To determine that a target is absent, one must believe that if the target were present, they would have been able to perceive it: a form of inference that requires counterfactual thinking and reliance on self-knowledge [@mazorInferenceAbsence2021]. Therefore, an alternative mechanism behind the longer search times in target-absent trials among OC+ participants could be a specific difficulty with inference about absence, rather than simply heightened sensitivity to uncertainty.

Clinical observations provide some support for the idea that people with OCD struggle with inferences about absence. One example is "Hit-and-run OCD", in which individuals feel compelled to mentally or physically retrace their driving route to ensure that they did not kill or injure someone while driving [@hyman2010]. This phenomenon manifests key properties of inference about absence: To conclude that an accident has not happened, a person needs to rely on the belief that if it did happen, they would have noticed it.

This clinical examples raise the possibility that the increased search time for target-absent trials may be due to a specific difficulty in inferring absence rather than a general intolerance of uncertainty. To test this idea, in two pre-registered online studies, we conducted a conceptual replication and a direct replication of the visual search study by @toffolo2013. Participants high and low in OCD tendencies were presented with visual search displays and asked to decide whether a target was absent or present. Experiment 1 aimed to elucidate whether the increased search times in target-absent trials for OC+ individuals are attributable to a specific difficulty with inference about absence or a general difficulty with handling uncertainty. Following our failure to replicate the original findings in this first experiment, Experiment 2 was designed as a more direct replication of @toffolo2013, using the exact same stimuli and instructions.

## Experiment 1

In Experiment 1, we sought to dissociate specific difficulties with inference about absence from more general difficulties with uncertainty by introducing an easy target-absent condition. To our surprise, we observed no group differences in target-absent search times, even for search displays that elicit high levels of uncertainty. We therefore focus our report here on this replication failure.

## Transparency and openness

We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study. All analysis scripts and anonymized data are available at github.com/Noamsarna/ocd_visual_search. The order and timing of experimental events were determined pseudo-randomly by the Mersenne Twister pseudorandom number generator, initialized to ensure registration time-locking (Mazor et al., 2019). A detailed preregistration document for Experiment 1 can be accessed at github.com/Noamsarna/ocd_visual_search/tree/main/experiments/Experiment1

```{r load_data, warning=FALSE, cache=TRUE, include=FALSE}

#load anon jatos data 
df<- read_csv('../data/anon_jatos_results_p1.csv')
df2<- read_csv('../data/anon_jatos_results_p2.csv')

df <- rbind(df, df2)
rm(df2)

#load anon prolific data 
demo_prolific <- read.csv('../data/anon_demo_prolific.csv')


# create OCI data ---------------------------------------------------------

#parse oci data from df 
OCI_df <- df %>%
  filter(grepl('oci', Identifier)) %>% 
  dplyr::select(subj_id, question, answer_oci) %>% 
  mutate(attention_check = question %in% c("OCI-Attention_check_1","OCI-Attention_check_2")) %>%
  arrange(subj_id, question)%>%
  #arrange it in a long format df 
  group_by(subj_id) %>%
  summarise(oci_overall=sum(as.numeric(answer_oci[!attention_check])), #compute oci general score 
            failed_attention_OCI = answer_oci[question=='OCI-Attention_check_1']!=0 | #attention check failure
            answer_oci[question=='OCI-Attention_check_2']!=2,
            OCI_Absent = answer_oci[question=='OCI-Absent']) %>%
  mutate(
  #split to quartiles based on oci score
    OCI_quantile = as.numeric(cut(oci_overall,
                                  breaks = quantile(oci_overall[!failed_attention_OCI],
                                                    probs = seq(0, 1, 0.25),
                                                    na.rm = T,
                                                    type = 9),
                                  right = F, 
                                  include.lowest = T,
                                  include.highest = T))
  )

# create DASS data ---------------------------------------------------------

#create vectors for DASS subscales. 
DASS_anxiety <- c("DASS-2", "DASS-4","DASS-7", "DASS-9", "DASS-15", "DASS-19", "DASS-20")
DASS_depression <- c("DASS-3","DASS-5", "DASS-10", "DASS-13", "DASS-16", "DASS-17","DASS-21")

#parse DASS data from df
DASS_df <- df %>%
  filter(grepl('DASS', Identifier)) %>% 
  dplyr::select(subj_id, question, answer_dass) %>% 
  arrange(subj_id, question) %>%
  #arrange in a new df 
  group_by(subj_id)%>%
  summarise(DASS_anxiety = sum(as.numeric(answer_dass[question %in% DASS_anxiety])),
            DASS_depression = sum(as.numeric(answer_dass[question %in% DASS_depression])))

# unite dass and oci
questionnaires_df <- left_join(OCI_df, DASS_df,by = "subj_id")

# plot OCI histogram  -----------------------------------------------------

#png("../ocd_visual_search/docs/figures/OCI_R_histogram.png", width = 1200, height = 800, res = 300)
hist(OCI_df$oci_overall, breaks = 'FD', xlab = "OCI-R total score", main = "OCI-R histogram", cex.main = 0.9,
     cex.lab = 0.75,)
#dev.off()

OCI_R_skewness <-skewness(OCI_df$oci_overall)
OCI_R_kurtosis <-kurtosis(OCI_df$oci_overall)

#pull quartile cutoff scores
oci_raw_quartiles <- OCI_df %>%
  filter(!failed_attention_OCI) %>%
  pull(oci_overall) %>%
  quantile(probs = seq(0, 1, 0.25), na.rm = TRUE, type = 9)

#pull OCI-R all items for computing alpha cronbach 
OCI_raw_items <-
  df %>%
  filter(grepl('oci', Identifier)) %>% 
  dplyr::select(subj_id, question, answer_oci) %>% 
  filter(!question %in% c('OCI-Attention_check_1', 'OCI-Attention_check_2','OCI-Absent')) %>% 
  pivot_wider(names_from = question, values_from = answer_oci)

#leave only quest items for internal consistency analysis 
OCI_raw_items <- OCI_raw_items %>% dplyr::select(-subj_id) 

#compute alpha cronbach for the OCI-R
OCI_alpha_cronbach<-
cronbach.alpha(OCI_raw_items)

#DASS histogram 
#anxiety 
#png("../ocd_visual_search/docs/figures/DASS_anx_hist.png", width = 1200, height = 800, res = 300)
hist(DASS_df$DASS_anxiety, breaks = 20, xlab = "DASS anxiety total score", main = "DASS anxiety histogram", cex.main = 0.9,
     cex.lab = 0.75, xlim = c(0, 20))
#dev.off()

#depression
#png("../ocd_visual_search/docs/figures/DASS_dep_hist.png", width = 1200, height = 800, res = 300)
hist(DASS_df$DASS_depression, breaks = 20, xlab = "DASS depression total score", main = "DASS depression histogram", cex.main = 0.9,
     cex.lab = 0.75, xlim = c(0, 20))
#dev.off()

#pull DASS items for internal consistency analysis 
DASS_raw_items <-
  df %>%
  filter(grepl('DASS', Identifier)) %>% 
  dplyr::select(subj_id, question, answer_dass) %>% 
  arrange(subj_id, question) %>% 
  pivot_wider(names_from = question, values_from = answer_dass)

#seperate into two df 
DASS_anx_df <- DASS_raw_items %>%
  dplyr::select(subj_id, all_of(DASS_anxiety)) %>% 
  dplyr::select(-subj_id)
  
DASS_dep_df <- DASS_raw_items %>%
  dplyr::select(subj_id, all_of(DASS_depression))%>% 
  dplyr::select(-subj_id)

#compute alpha cronback for dass anxiety sub scale 
DASS_anx_alpha_cronbach<-
  cronbach.alpha(DASS_anx_df)

#compute alpha cronback for dass depression sub scale
DASS_dep_alpha_cronbach<-
  cronbach.alpha(DASS_dep_df)

# df of explicit difficulty rating---------------------------------------------------

#get data from df 
difficulty_rating <- df %>% 
  filter(trial_type == "html-slider-response") %>% 
  dplyr::select(subj_id,test_part,response) %>%
  #retrieve variable names. 
  mutate(difficulty_rating = case_when(str_detect(test_part,"PresentOinC25") ~ "OinC_25_TP",
                                       str_detect(test_part,"Absent09") ~ "CinO_9_TA",
                                       str_detect(test_part,"PresentOinC09") ~ "OinC_9_TP",
                                       str_detect(test_part,"Absent25") ~ "CinO_25_TA")) %>% 
  dplyr::select(-test_part) %>% 
  
  #adding OCI quantile to difficulty df 
  left_join(questionnaires_df %>% 
              group_by(subj_id) %>%
              summarise(OCI_quantile=first(OCI_quantile)) %>% 
              dplyr::select(subj_id, OCI_quantile), 
            difficulty_rating,
            by = "subj_id")

# visual search df -------------------------------------------------------------

search_df <- df %>% 
  filter(trial_type == "p5vs_yn_small_grid") %>%
  dplyr::select(trial_type,trial_index,subj_id,sequence,target_position,
          subj_id,set_size,target_present,
         RT,test_part,correct,search_type) %>% 
# unite search and questionnaire dfs together 
  left_join(questionnaires_df,
                       by = "subj_id") %>% 
  #unite search df with demo prolific 
  left_join(.,demo_prolific,
            by = "subj_id")

#recode variables 
search_df$target_present<-search_df$target_present=='TRUE'
search_df$RT <- as.numeric(search_df$RT)
search_df$correct <- as.numeric(as.logical(search_df$correct))
search_df$set_size <- as.factor(search_df$set_size)
 
#N total before exclusion 
df.N_before_exclusion <- search_df$subj_id %>% unique() %>% length()


# Rejecting participants with more than 15% error trials -----------------------

rejection_df <- search_df %>% 
  group_by(subj_id, OCI_quantile) %>% 
  summarise(accuracy = mean(correct),
            mean_error=1-accuracy) %>% 
  mutate(reject = accuracy<0.85)

# flag bad trails (shorter than 100ms)
search_df <- search_df %>% rowwise() %>% 
  mutate(under_100 = as.numeric(RT <= 100)) 

# count if there are participants with more than 25% of trials below 100 ms. 
participant_short_trials<-
search_df %>% 
  group_by(subj_id) %>%
  summarize(count_under_100 = sum(under_100 == 1))

#No participants with more than 25% error trials. 

#filter out participants for accuracy and attention check 
search_df <- left_join(search_df, 
                       rejection_df %>% dplyr::select(subj_id, reject), 'subj_id') %>%
  filter(reject=='FALSE' & failed_attention_OCI == 0) %>%
  filter(under_100 == 0)  #filter our trials 
  

#total n after participants removal 
df.N_after_exclusion <- search_df$subj_id %>% unique() %>% length()
total_excluded <- df.N_before_exclusion - df.N_after_exclusion

#total n in each quartile 
#search_df %>% dplyr::select(subj_id, OCI_quantile) %>% unique() %>% dplyr::select(OCI_quantile) %>% table()

# Accuracy comparison  ----------------------------------------------------
#descriptive 
exp1_acc_df <-
search_df %>% 
  group_by(subj_id, OCI_quantile, target_present) %>% 
  summarise(accuracy = mean(correct))

exp1_acc_stats<-            
exp1_acc_df %>% filter(OCI_quantile==1 | OCI_quantile==4) %>%
  group_by(OCI_quantile) %>% 
  summarise(mean_acc = mean(accuracy))

#t.test compare groups accuracy
exp1_acc_t_test<-
exp1_acc_df %>% filter(OCI_quantile==1 | OCI_quantile==4) %>% group_by(subj_id, OCI_quantile) %>% summarise(mean_acc=mean(accuracy)) %>%
  ungroup() %>% 
  t.test(mean_acc~OCI_quantile, data=., alternative="two.sided")

# Descriptive stats  ---------------------------------------------------- 
# create function to calculate percentages for a given column in demographic

calculate_percentage <- function(data, column_name) {
  counts <- data %>%
    filter(!!sym(column_name) != "DATA_EXPIRED") %>%
    count(!!sym(column_name)) %>%
    rename(Category = !!sym(column_name), Count = n)

  total_count <- sum(counts$Count)

  counts %>%
    mutate(Percentage = round((Count / total_count) * 100, 2))
}

# Calculate percentages for ethnicity, sex, nationality, and employment Status
ethnicity_percentage <- calculate_percentage(demo_prolific, "Ethnicity.simplified")
sex_percentage <- calculate_percentage(demo_prolific, "Sex")
nationality_percentage <- calculate_percentage(demo_prolific, "Nationality")
employment_percentage <- calculate_percentage(demo_prolific, "Employment.status")

# Mean and sd of age
age_stats <- demo_prolific %>%
  summarise(Mean_Age = round(mean(as.numeric(Age), na.rm = TRUE), 2),
            SD_Age = round(sd(as.numeric(Age), na.rm = TRUE), 2))

```

# Methods

# Participants

The research was approved by the Research Ethics Committee of Tel-Aviv University (study ID number 0004169-1). One thousand and seven participants were recruited via Prolific (<https://prolific.co/>) and selected based on their acceptance rate (\>95%) and for being native English speakers, located in the UK. The median completion time for the entire experiment was 14 minutes. Participants were paid £2 for their participation, equivalent to an hourly wage of £8.57. Participants were divided into high (OC+) and low (OC-) OCD tendencies groups based on their scores in the OCI-R (Foa et al., 2002; see below), with the OC+ group consisting of those in the highest quartile of the OCI-R scores distribution and the OC- group comprising those in the lowest quartile of this distribution. The entire sample (n=1007) completed the visual search task. Due to higher-than-expected exclusion rate, and in deviation from our pre-registered plan to collect 250 participants in each group, our final sample included 213 OC+ participants and 220 OC- participants.

The average age of the total sample was `r printnum(age_stats$Mean_Age)` years (SD = `r printnum(age_stats$SD_Age)`). Half of the sample identified as female. In terms of ethnicity, the majority (`r printnum(round(max(ethnicity_percentage$Percentage,0)))`) identified as White, followed by Asian (7%), Black (4%), and Mixed/Other (5%). The predominant nationality was UK (93%). Employment status was predominantly full-time (62%), followed by part-time (16%).

# Visual search task

The visual search task consisted of four blocks, each containing 24 trials of searching for either a closed or an open square. The task began with a practice phase consisting of one block with six trials. Each display was presented for a maximum of 10 seconds or until a response was received. During the practice phase, feedback about accuracy was given after each trial: If the response was correct, the word "Correct!" appeared on the screen for one second; If the response was wrong, the word "Wrong" appeared on the screen for 5 seconds. In the main part of the experiment, no feedback was given, as was the case in the original paradigm [@toffolo2013]. After completing the practice, participants looked for either a closed square among rotated open squares ('hard search'; Fig. 1, main part, right panel), or for a rotated open square among closed squares ('easy search'; Fig. 1, main part, left panel). The difference in difficulty between these two search types is due to a search asymmetry for open/closed edges [@treisman1988]. We further manipulated target presence and set size, resulting in a 2X2X2 design (Search type: 'easy-search' or 'hard-search'; Target: present/absent; Set size: 9 or 25). Block order was counterbalanced between participants, and trial order within individual blocks was fully randomized (figure 1).

# Measures

# Obsessive--Compulsive Inventory-Revised (OCI-R; Foa et al., 2002).

The OCI-R is an 18-item self-report measure of OCD symptom severity. Responders are asked to rate their level of distress pertaining to 18 statements in the past month on a five-point scale ranging from 0 (Not at all) to 4 (Extremely). The OCI-R has been shown to have good validity, test-retest reliability and internal consistency in both clinical [@foa2002] and non-clinical samples [@hajcak2004].

# Depression, Anxiety and Stress Scales-21 (DASS-21; Lovibond & Lovibond, 1995).

The DASS-21 is a 21- item self-report questionnaire that is divided into three seven-item subscales to measure dimensional components of depression, anxiety, and stress. ). Each individual item refers to the respondent's experiences over the past week and is evaluated on a four-point scale, ranging from 0 ('the item does not apply to me at all') to 3 ('the item applies to me very much or most of the time'). The DASS-21 has shown high reliability, validity, and internal consistency within both clinical groups and community sample [@lovibond1995; @antonyPsychometricProperties42Item; @henry2005]. In this study only the depression and anxiety scales were used. We used the depression and anxiety sub-scales to control for non-specific effects associated with OCD tendencies.

## Procedure

A static version of Experiment 1 can be accessed at: <https://noamsarna.github.io/ocd_visual_search/experiments/demos/exp1/>. Participants were first instructed about the experiment's structure, which comprised three parts: a visual search task, questions about the visual search, and the two inventories: OCI-R and DASS-21. Then, they received written instructions about the visual search task. After completing the visual search task, participants were asked to rate the difficulty of noticing the presence or absence of a certain target among different distractors (more information about this in the appendix). Following the difficulty estimation, participants completed the OCI-R and DASS-21. We included two attention check questions among the OCI-R items, asking participants to select a certain answer ('If you read this question, check the option 'Not at all').

```{r figure_1, fig.cap="Figure 1 - Overview of experimental Design. Top panel: each visual search trial started with a centered black fixation cross. Middle panel (Practice): After reading the instructions, participants completed practice trials, searching for a rotated T among rotated L's in 6-trial blocks until they achieved a minimum accuracy of 0.83 (no more than one error). Middle panel (Main part): The primary experiment comprised 96 trials in four blocks, with the target identity changing after two blocks. Each 24-trial block followed a 2x2 design, manipulating set size (9 or 25) and target presence (present/absent). Bottom panel: Search difficulty estimation: participants used their mouse to rate search difficulty on a continuous scale. In questions about target-present searches, the target was marked with a red square."}
knitr::include_graphics("figures/figure_1.png")
```

## Data Analysis

# Exclusion Criteria

Participants were excluded from the analysis if they made more than 15% errors in the main part of the experiment or for having extremely fast or slow reaction times (below 100 milliseconds) in more than 25% of the trials. Participants were also excluded if they failed one or more of the attention checks. In total, 109 out of 1007 participants were excluded from the analysis. For the remaining participants, error trials and trials with response times below 100 milliseconds were excluded from the response-time analysis.

```{r analyze_data, cache=TRUE, include=FALSE}

# Perceived difficulty pre-processing -------------------------------------

difficulty_rating_by_condition <- difficulty_rating %>% 
  mutate(condition=case_when(str_detect(difficulty_rating, "_TA") ~ "Absent",
                             str_detect(difficulty_rating, "_TP") ~ "Present")) %>% 
  group_by(difficulty_rating, condition) %>%
  summarise(mean = mean(as.numeric(response), na.rm = T),
            sd = sd(as.numeric(response), na.rm = T)) %>% 
  ungroup() 

#difficulty rating with oc quantile 
difficulty_rating_by_condition_with_oci <- difficulty_rating %>% 
  mutate(condition=case_when(str_detect(difficulty_rating, "_TA") ~ "Absent",
                             str_detect(difficulty_rating, "_TP") ~ "Present")) %>% 
  group_by(difficulty_rating, condition, OCI_quantile) %>%
  summarise(mean = mean(as.numeric(response), na.rm = T),
            sd = sd(as.numeric(response), na.rm = T)) %>% 
  ungroup() %>% 
  filter(OCI_quantile=='1' | OCI_quantile=='4') %>% 
  mutate(OCI_quantile_factor = recode(OCI_quantile, '1'='low', '4'='high'))

# Summary dfs  ------------------------------------------------------------

#create a df in which every participant gets a mean score for each search option (8)
search_summary <- 
  search_df %>% 
  filter(correct==1) %>% #only correct trials 
  group_by(subj_id, set_size,search_type, target_present, OCI_quantile) %>% 
  summarise(mean_rt = mean(RT, na.rm = T),
            median_rt = median(RT, na.rm = T)) %>%
  ungroup() 

toffolo_data <- search_df %>%
  filter(set_size == 25) %>% 
  filter(search_type == "OinC") %>% 
  arrange(subj_id, target_present)

by_sub_toffolo <- toffolo_data %>% 
  group_by(subj_id, target_present, OCI_quantile, 
           oci_overall,
           DASS_anxiety, DASS_depression, Age) %>% 
  summarise(N = n(),
            mean_RT = mean(RT, na.rm = T),
            median_RT = median(RT, na.rm = T),
            sd_RT = sd(RT, na.rm = T)) %>% ungroup() %>% 
  mutate(log_mRT = log(mean_RT))

# Extracting slopes ------------------------------------------------------------------

#Reordering set size to get the slopes for the effect of going from 9 to 25. 
search_df$set_size <- relevel(as.factor(search_df$set_size), '9')

#extracting slopes 
search_slopes_df <- search_df %>%
  filter(correct==1) %>% #only correct trials 
  group_by(subj_id,search_type,target_present) %>%
  nest() %>%
  mutate(model = map(data, ~ lm(RT ~ set_size, data =.)),
         tidy = map(model, ~ tidy(.x))) %>%
  unnest(tidy) %>%
  # we are interested in the slope, i.e., the effect of set size.
  filter(term=='set_size25')

search_slopes_df<- left_join(search_slopes_df, questionnaires_df %>% 
                               dplyr::select(subj_id, OCI_quantile, oci_overall, DASS_depression, DASS_anxiety),
                             by='subj_id') 



slopes_table <-search_slopes_df %>% 
  group_by(OCI_quantile, search_type, target_present) %>% 
  summarise(mean(estimate)) %>%
  filter(OCI_quantile==1 | OCI_quantile==4)


```

```{r DR_h3, cache=TRUE, include=FALSE}
  
  # Toffolo replication plots -----------------------------------------------------

exp1_mean_RT_fig <- by_sub_toffolo%>% 
    filter(OCI_quantile == 1 | OCI_quantile == 4) %>% 
    mutate(oci_type = ifelse(.$OCI_quantile == 1, "Low OC (OC-)", "High OC (OC+)")) %>% 
    dplyr::select(subj_id, target_present, oci_type, mean_RT)  %>%
    ggplot(aes(x = target_present, y = mean_RT,  group = oci_type, shape = oci_type)) +
    stat_summary(fun = mean,
                 geom = "point",
                 position = position_dodge(0.9),
                 size = 5) +
    stat_summary(fun.data = mean_se,
                 geom = "errorbar",
                 width = 0.4,
                 position = position_dodge(0.9)) +
    scale_shape_manual(values = c("High OC (OC+)" = 1, "Low OC (OC-)" = 2)) +
    scale_x_discrete(labels = c("FALSE" = "Absent", "TRUE" = "Present")) +
    theme_bw() +
    theme(axis.title.x = element_blank(),
          text = element_text(size = 12)) +
    ylab('Mean RT (ms)')+
    labs(shape = "OC group")+ 
    coord_cartesian(ylim = c(2500,7500))
  
  
#ggsave(filename = "exp_1_results.png",width = 4, height = 3, dpi = 1500)  


H3.df <- toffolo_data %>% 
  filter(OCI_quantile==1| OCI_quantile==4) %>%
  group_by(subj_id, OCI_quantile, target_present) %>%
  summarise(mean_RT=mean(RT)) %>% 
  ungroup()

#Bayes factor analysis -----------------------------------------------------
# Convert independent variables to factors
H3.df$OCI_quantile <- factor(H3.df$OCI_quantile)
H3.df$target_present <- factor(H3.df$target_present)
H3.df$subj_id <- factor(H3.df$subj_id)

#Create a new df for the T test of difference Bayesian analysis 
H3.df_mean_diff <- 
  H3.df%>%
  group_by(subj_id, OCI_quantile) %>%
  summarise(diff_mean_RT = mean(mean_RT[target_present == "FALSE"]) - mean(mean_RT[target_present == "TRUE"])) %>%
  ungroup() 

#Bayesien t-test 
Exp1.bayes_t_test <-
ttestBF(formula =diff_mean_RT ~ OCI_quantile, data = H3.df_mean_diff, rscale = 0.4, nullInterval = c(-Inf,0))

#cohen's D
exp_1_H3_cohenD<-
H3.df_mean_diff %>% cohens_d(diff_mean_RT~OCI_quantile, var.equal = TRUE)

```

```{r h1_h2_t-test, echo=FALSE, cache=TRUE}
#creating a df for second hypothesis testing 

H1.desc <- search_slopes_df %>% group_by(search_type) %>%  
  summarise(mean_slope = mean(estimate),
            ms_item = mean_slope/(25-9))

H2.df<- search_slopes_df %>% 
  filter(target_present==TRUE & search_type=='OinC' |target_present==FALSE & search_type=='CinO')  %>% 
  mutate(group = case_when(search_type == 'OinC' ~ 'hard_present',
                           search_type == 'CinO' ~ 'easy_absent'));
                          
H2.desc <- H2.df %>% 
  group_by(group) %>% 
  summarise(mean_slope=mean(estimate),
            ms_item = mean_slope/(25-9))

```

```{r h4_anova, echo=FALSE, cache=TRUE}

H4.df<- search_slopes_df %>% 
  filter(OCI_quantile==1 | OCI_quantile==4) %>% 
  filter(search_type=='OinC')
                          
H4.desc <- H4.df %>% group_by(OCI_quantile, target_present) %>% summarise(mean_slope = mean(estimate))

```

```{r h5_anova, echo=FALSE, cache=TRUE}
H5.df <- search_slopes_df %>% filter(OCI_quantile==1| OCI_quantile==4) %>% filter(search_type=='CinO')

```

```{r model_comparison, echo=FALSE, cache=TRUE}

#We didn't use LOOCV since we included random terms in our model. So instead we compared models by their AIC and BIC values.  

m1 <- 
  search_slopes_df%>% 
  filter(OCI_quantile==1|OCI_quantile==4) %>% 
  mutate(OCI_group = recode(OCI_quantile, '1'='low', '4'='high')) %>% 
  
  lmer(estimate ~ 1+OCI_group+ search_type * target_present +search_type *OCI_group+
         (search_type+target_present|subj_id), #random slope for search type and target present for each participant 
        data =.)

#examine model parameters 
#parameters::model_parameters(m1, ci_method= 's')

m2 <- 
  search_slopes_df%>% 
  filter(OCI_quantile==1|OCI_quantile==4) %>% 
  mutate(OCI_group = recode(OCI_quantile, '1'='low', '4'='high')) %>% 
  
  lmer(estimate ~ 1+OCI_group+ search_type * target_present +target_present *OCI_group+
         (search_type+target_present|subj_id), #random slope for search type and target present for each participant 
        data = .)

#examine model parameters 
#parameters::model_parameters(m2, ci_method= 's')

#create models table (table 1)
H6.model_acc_table <-as.data.frame(compare_accuracy(m1, m2))  %>% 
  dplyr::select(Model, AIC) 

#scale AIC values to zero 

scaled_AIC_m1 =H6.model_acc_table$AIC[1] - H6.model_acc_table$AIC[1] 
scaled_AIC_m2 =H6.model_acc_table$AIC[2] - H6.model_acc_table$AIC[1]

H6.model_acc_table$scaled_AIC <- c(scaled_AIC_m1, scaled_AIC_m2)


#extract model formula (fixed variables only) 
m1_formula <- paste(deparse(formula(m1, fixed.only = T), width.cutoff = 500), collapse = " ")
m2_formula <- paste(deparse(formula(m2, fixed.only = T), width.cutoff = 500), collapse = " ")

H6.model_acc_table$formula <- c(m1_formula, m2_formula)

```

```{r first_trials, cache=TRUE, include=FALSE}
# correct trial order effects

first_trials_df <- search_df %>%
  filter(test_part=='first_two_trials' & correct) %>%
  group_by(subj_id) %>%
  filter(n()==4) %>% #include only subjects who have a valid 4 first trials
  arrange(trial_index) %>%
  mutate(trial_index = seq(n()), #standardizing trial order across participants
  mean_subj_RT = mean(RT)) %>%
  group_by(trial_index) %>%
  mutate(mean_position_RT = mean(RT)) %>%
  ungroup() %>%
  mutate(corrected_RT = RT-mean_position_RT+mean_subj_RT)

  first_trials_df %>% 
  group_by(search_type, set_size) %>% 
  summarise(median_RT =median(corrected_RT)) %>% 
  ggplot(data=. , 
       aes(x=set_size, y=median_RT, color=search_type, fill=search_type, linetype=search_type)) +
  geom_line(aes(group = search_type), size=1) +
  geom_point(aes(shape = search_type), size=4, color="black",stroke=1.5, alpha=0.8) +
  scale_shape_manual(values=c(4,22))+
  scale_fill_manual(values = c('black',"#e41a1c"))+
  scale_color_manual(values = c('black',"#e41a1c"))+
  scale_linetype_manual(values=c("21", "solid","21"))+
  #ylim(900, 2000)+
  scale_x_discrete(limits = c("9", "25")) +
  labs(title="First trials full sample", y='median RT', x='set size') +
  geom_label(aes(label=round(median_RT,2)), color='white')

search_slopes_df_first_t <- first_trials_df %>%
  filter(OCI_quantile==1|OCI_quantile==4) %>% 
  group_by(subj_id,search_type,target_present, test_part,OCI_quantile) %>%
  nest() %>%
  mutate(model = map(data, ~ lm(corrected_RT ~ set_size, data =.)),
         tidy = map(model, ~ tidy(.x))) %>%
  unnest(tidy) %>%
  filter(term=='set_size25') %>% 
  filter(test_part=='first_two_trials')

search_slopes_first_trials_desc <- search_slopes_df_first_t %>% 
  group_by(search_type) %>% 
  summarise(mean_slope=mean(estimate),
            sd_slope = sd(estimate),
            ms_item = mean_slope/(25-9))

#figure
First_trials_OC_groups<-
  search_df %>% 
  filter(test_part=='first_two_trials') %>% 
  filter(OCI_quantile==1|OCI_quantile==4) %>% 
  group_by(subj_id, search_type, set_size, OCI_quantile) %>% 
  summarise(mean_RT =mean(RT)) %>% 
    group_by(search_type, set_size, OCI_quantile) %>% 
    summarise(mean_RT =mean(mean_RT)) %>% 
  ggplot(data=. , 
       aes(x=set_size, y=mean_RT, color=search_type, fill=search_type, linetype=search_type)) +
  geom_line(aes(group = search_type), size=1) +
  geom_point(aes(shape = search_type), size=4, color="black",stroke=1.5, alpha=0.8) +
  facet_wrap(~OCI_quantile)+
  scale_shape_manual(values=c(4,22))+
  scale_fill_manual(values = c('black',"#e41a1c"))+
  scale_color_manual(values = c('black',"#e41a1c"))+
  scale_linetype_manual(values=c("21", "solid","21"))+
  scale_x_discrete(limits = c("9", "25"))+labs(title="First trials full sample")+geom_label(aes(label=round(mean_RT,2)), color='white')


```

```{r H9_full_range, include=FALSE}

m3 <-
  lmer(estimate ~ 1+oci_overall+ search_type * target_present +target_present *oci_overall+ 
            (search_type+target_present|subj_id), #random slope for search type and target present for each participant 
               data = search_slopes_df)

```

```{r DASS_mediation, cache=TRUE, include=FALSE}

m4 <-lmer(estimate ~ 1+search_type * target_present +target_present *OCI_quantile+
               DASS_anxiety+DASS_depression+
              (search_type+target_present|subj_id),#random slope for search type and target present for each participant 
               data = search_slopes_df %>% filter(OCI_quantile==1| OCI_quantile==4))

```

```{r explicit_dif, cache=TRUE, include=FALSE}

#create a df in the same format as the difficulty df, so include only 4 searches of difficulty estimation:
#hard present and easy absent with both set sizes. 

search_correlation <- search_summary %>% 
  filter(search_type=='CinO' & set_size=='9' & target_present=='FALSE'| #easy absent small set size
           search_type=='CinO' & set_size=='25' & target_present=='FALSE'| #easy absent big set size 
           search_type=='OinC' & set_size=='9' & target_present=='TRUE'| #hard present small set size
           search_type=='OinC' & set_size=='25' & target_present=='TRUE') %>% #hard present big set size 
  mutate(target_present =case_when(target_present=='TRUE' ~ 'TP', #change names 
                                   target_present=='FALSE' ~ 'TA')) %>% 
  unite('difficulty_rating', c(search_type, set_size, target_present), remove = F) #create names like in the difficulty df 

#combine with the difficulty df 
search_correlation<- left_join(search_correlation, difficulty_rating %>% dplyr::select(-OCI_quantile))

search_correlation_wide <- search_correlation %>%
  dplyr::select(subj_id, set_size, search_type, target_present, OCI_quantile, mean_rt, response) %>% 
  pivot_wider(
    names_from = c(search_type, target_present, set_size),
    values_from = c(mean_rt, response))

search_correlation_wide <- search_correlation_wide %>% 
  mutate(slope_easy_absent = mean_rt_CinO_TA_25 - mean_rt_CinO_TA_9,
         slope_hard_present = mean_rt_OinC_TP_25- mean_rt_OinC_TP_9) 

search_correlation_wide %>% 
  dplyr::select(slope_easy_absent, slope_hard_present) %>% 
  summarise(mean_slope_easy_absent = mean(slope_easy_absent),
            mean_slope_hard_present = mean(slope_hard_present))


#plot for the entire sample 

p1<-
search_correlation %>% 
ggplot(aes(x = set_size, y = mean_rt, fill = target_present, shape = target_present)) +
  stat_summary(fun = mean, 
               geom = 'point',
               position = position_dodge(0.9),
               size = 5,
               alpha = 0.6) +
  stat_summary(fun.data = mean_se,
               geom = 'errorbar',
               position = position_dodge(0.9), 
               width = 0.4) +
  stat_summary(fun = mean,
               geom = 'line', 
               aes(group = target_present),
               position = position_dodge(0.9),
               alpha = 0.6) +
  labs(x = 'Set Size', 
       y = 'RT ms', 
       title = 'Reaction times', 
       subtitle = 'Entire sample')+
  guides(fill = FALSE,
         shape = guide_legend(title = "Trial type")) +
  scale_fill_manual(labels = c('Easy target-absent', 'Hard target-present'),values = wes_palette("Royal1")) +
  scale_shape_manual(values = c(21, 24), 
                     labels = c('Easy target-absent', 'Hard target-present')) +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))+
   coord_cartesian(ylim = c(1400,2800))


#plot for the OC- group  

p2<-
  search_correlation %>% 
  filter(OCI_quantile==4) %>% 
  ggplot(aes(x = set_size, y = mean_rt, fill = target_present, shape = target_present)) +
  stat_summary(fun = mean, 
               geom = 'point',
               position = position_dodge(0.9),
               size = 5,
               alpha = 0.6) +
  stat_summary(fun.data = mean_se,
               geom = 'errorbar',
               position = position_dodge(0.9), 
               width = 0.4) +
  stat_summary(fun = mean,
               geom = 'line', 
               aes(group = target_present),
               position = position_dodge(0.9),
               alpha = 0.6) +
  labs(x = 'Set Size', 
       y = 'RT ms', 
       title = 'Reaction times', 
       subtitle = 'OC+')+
  guides(fill = FALSE,
         shape = guide_legend(title = "Trial type")) +
  scale_fill_manual(labels = c('Easy target-absent', 'Hard target-present'),values = wes_palette("Royal1")) +
  scale_shape_manual(values = c(21, 24), 
                     labels = c('Easy target-absent', 'Hard target-present')) +
  theme(axis.title.y = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))+
  coord_cartesian(ylim = c(1400,2800))


#plot for the OC+ group  

p3<-
  search_correlation %>% 
  filter(OCI_quantile==1) %>% 
  ggplot(aes(x = set_size, y = mean_rt, fill = target_present, shape = target_present)) +
  stat_summary(fun = mean, 
               geom = 'point',
               position = position_dodge(0.9),
               size = 5,
               alpha = 0.6) +
  stat_summary(fun.data = mean_se,
               geom = 'errorbar',
               position = position_dodge(0.9), 
               width = 0.4) +
  stat_summary(fun = mean,
               geom = 'line', 
               aes(group = target_present),
               position = position_dodge(0.9),
               alpha = 0.6) +
  labs(x = 'Set Size', 
       y = 'RT ms', 
       title = 'Reaction times', 
       subtitle = 'OC-')+
  guides(fill = FALSE,
         shape = guide_legend(title = "Trial type")) +
  scale_fill_manual(labels = c('Easy target-absent', 'Hard target-present'),values = wes_palette("Royal1")) +
  scale_shape_manual(values = c(21, 24), 
                     labels = c('Easy target-absent', 'Hard target-present')) +
  theme(axis.title.y = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))+
  coord_cartesian(ylim = c(1400,2800))


#difficulty figures p4-p6 
p4 <- 
  search_correlation %>% 
  ggplot(aes(x = set_size, y = as.double(response), fill = target_present, shape = target_present)) +
  stat_summary(fun = mean, 
               geom = 'point',
               position = position_dodge(0.9),
               size = 5,
               alpha = 0.6) +
  stat_summary(fun.data = mean_se,
               geom = 'errorbar',
               position = position_dodge(0.9), 
               width = 0.4) +
  stat_summary(fun = mean,
               geom = 'line', 
               aes(group = target_present),
               position = position_dodge(0.9),
               alpha = 0.6) +
  labs(x = 'Set Size', 
       y = 'Response', 
       title = 'Difficulty rating', 
       subtitle = 'Entire sample')+
  guides(fill = FALSE,
         shape = guide_legend(title = "Trial type")) +
  scale_fill_manual(labels = c('Easy target-absent', 'Hard target-present'),values = wes_palette("Royal1")) +
  scale_shape_manual(values = c(21, 24), 
                     labels = c('Easy target-absent', 'Hard target-present')) +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))+
  coord_cartesian(ylim = c(30,80))

p5 <- 
  search_correlation %>% 
  filter(OCI_quantile==4) %>% 
  ggplot(aes(x = set_size, y = as.double(response), fill = target_present, shape = target_present)) +
  stat_summary(fun = mean, 
               geom = 'point',
               position = position_dodge(0.9),
               size = 5,
               alpha = 0.6) +
  stat_summary(fun.data = mean_se,
               geom = 'errorbar',
               position = position_dodge(0.9), 
               width = 0.4) +
  stat_summary(fun = mean,
               geom = 'line', 
               aes(group = target_present),
               position = position_dodge(0.9),
               alpha = 0.6) +
  labs(x = 'Set Size', 
       y = 'Response', 
       title = 'Difficulty rating', 
       subtitle = 'OC+')+
  guides(fill = FALSE,
         shape = guide_legend(title = "Trial type")) +
  scale_fill_manual(labels = c('Easy target-absent', 'Hard target-present'),values = wes_palette("Royal1")) +
  scale_shape_manual(values = c(21, 24), 
                     labels = c('Easy target-absent', 'Hard target-present')) +
  theme(axis.title.y = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))+
  coord_cartesian(ylim = c(30,80))

p6 <- 
  search_correlation %>% 
  filter(OCI_quantile==1) %>% 
  ggplot(aes(x = set_size, y = as.double(response), fill = target_present, shape = target_present)) +
  stat_summary(fun = mean, 
               geom = 'point',
               position = position_dodge(0.9),
               size = 5,
               alpha = 0.6) +
  stat_summary(fun.data = mean_se,
               geom = 'errorbar',
               position = position_dodge(0.9), 
               width = 0.4) +
  stat_summary(fun = mean,
               geom = 'line', 
               aes(group = target_present),
               position = position_dodge(0.9),
               alpha = 0.6) +
  labs(x = 'Set Size', 
       y = 'Response', 
       title = 'Difficulty rating', 
       subtitle = 'OC-')+
  guides(fill = FALSE,
         shape = guide_legend(title = "Trial type")) +
  scale_fill_manual(labels = c('Easy target-absent', 'Hard target-present'),values = wes_palette("Royal1")) +
  scale_shape_manual(values = c(21, 24), 
                     labels = c('Easy target-absent', 'Hard target-present')) +
  theme(axis.title.y = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))+
  coord_cartesian(ylim = c(30,80))

# plot together  ------------------------------------------------------------
# Define color and shape vectors for convenience
my_colors <- wes_palette("Royal1")[1:2]
my_shapes <- c(21, 24)

# Remove the legend from each plot and add y-axis label for the first plot of each row
p1 <- p1 + theme(legend.position = "none") + ylab("RT ms")
p2 <- p2 + theme(legend.position = "none")
p3 <- p3 + theme(legend.position = "none")
p4 <- p4 + theme(legend.position = "none") + ylab("Response")
p5 <- p5 + theme(legend.position = "none")

# Ensure that colors and shapes are correctly set in p6
p6 <- p6 + 
  scale_fill_manual(values = my_colors, labels = c('Easy target-absent', 'Hard target-present'), name = NULL) +
  scale_shape_manual(values = my_shapes, labels = c('Easy target-absent', 'Hard target-present'), name = NULL) +
  guides(fill = guide_legend(override.aes = list(fill = my_colors)),
         shape = guide_legend(override.aes = list(shape = my_shapes))) +
  theme(legend.position = "bottom", legend.text = element_text(size = 12))

#remove the white background from the legend 
p6 <- p6 + theme(legend.background = element_blank(),
                 legend.box.background = element_blank(),
                 legend.box.margin = margin(0, 0, 0, 0),
                 legend.key = element_blank())

# Extract the legend
common_legend <- cowplot::get_legend(p6)

# Remove the legend from p6
p6 <- p6 + theme(legend.position = "none")

# Arrange the plots with the common legend at the bottom
combined_plot <- cowplot::plot_grid(
  cowplot::plot_grid(p1, p2, p3, ncol = 3),
  cowplot::plot_grid(p4, p5, p6, ncol = 3),
  common_legend,
  ncol = 1,
  rel_heights = c(1, 1, 0.1)  # Relative heights of rows (adjust as needed)
)

#ggsave(filename = "RT_and_estimation.png",width = 8, height = 6, dpi = 1000, path="./figures")  


```

# Results

We focus our report here on our failure to replicate a group difference in target-absent search times, even for search displays that elicit high levels of uncertainty. All additional analysis from our preregistered hypotheses can be found in the appendix of this paper.

# Replication of group differences in target-absent RT

To directly replicate group differences in target-absent response time (RT) (Toffolo et al., 2013, 2014, 2016), we focused on the difficult search with the larger set size (set size = 25). We conducted a mixed-effects ANOVA, with mean response time (RT) as the dependent variable, group (OC+ vs. OC-) as a between-subjects variable, and target presence (present vs. absent) as a within-subjects variable. Specifically, we examined the interaction effect testing the hypothesis that the mean RT difference between the OC+ and OC- groups would be significantly more pronounced in target-absent trials. Contrary to our expectations, the analysis did not reveal a significant interaction between group and target presence, `r apa_print(afex::aov_ez("subj_id", "mean_RT", H3.df, between = "OCI_quantile", within = "target_present"))$statistic$OCI_quantile_target_present`, Cohen's *d*= `r print_num(exp_1_H3_cohenD$effsize)` (figure 2, Exp1). A null result was also obtained in a correlation analysis, pooling data from all participants and treating OCI scores as a continuous variable (see Supplementary materials, pre-registered hypothesis 9). To quantify the evidence for the null we conducted a Bayesian t-test setting the scale at the averaged effect size found in Toffolo et al., (2013, 2014) reflecting a belief that if present, group differences should be negative and moderate in size [@rouderBayesian]. A one-sided Bayesian independent samples t-test produced a Bayes Factor of `r apa_print(Exp1.bayes_t_test, scientific_threshold = c(min = 1e-10, max = 1e10))$statistic$interval`, providing strong evidence for the null hypothesis of no group differences.

We conducted several additional analyses that examine the interaction between the OC groups and the presence of the target. First, at the group level, we performed multi-level regression, accounting for anxiety and depression. We found no interaction between the OC groups and the presence of the target (preregistered hypothesis 10; `r apa_print(m4)$full_result$target_presentTRUE_OCI_quantile`). Similarly, when we focused on the initial trials of the task, prior to any accumulated experience (preregistered hypothesis 8), we found no interaction between group and target presence in a mixed-effects ANOVA (`r apa_print(afex::aov_ez("subj_id", "estimate", search_slopes_df_first_t, between = "OCI_quantile", within = "search_type"))$statistic$OCI_quantile_search_type`). Furthermore, at the group level, we observed no significant differences between the groups in their self-reported measures of task difficulty. A group difference in accuracy did reach significance, such that the OC+ group (*M*=`r print_num(exp1_acc_stats$mean_acc[exp1_acc_stats$OCI_quantile=='4'])`) was overall less accurate than the OC- group (*M*=`r print_num(exp1_acc_stats$mean_acc[exp1_acc_stats$OCI_quantile=='1'])`; `r apa_print(exp1_acc_t_test)$statistic`). Importantly, this difference did not replicate in Experiment 2. To extend our analysis to the entire sample, encompassing the four OCI-R quartiles, we replaced the group variable (OC+; OC-) with the full range of OCI-R scores. In this analysis, we still found no interaction between OCI-R scores and the presence of the target (preregistered hypothesis 9; `r apa_print(m3)$full_result$oci_overall_target_presentTRUE`. Detailed calculations and results for all these hypotheses are provided in the Appendix for further reference.

## Experiment 2

In Experiment 1, target-absent search times were not significantly slower in OC+ compared to OC- individuals. While this stands in contrast to previous reports (Toffolo et al., 2013, 2014, 2016), our results differed from those of the original study in other respects as well. Most notably, search times in this study (\~4.5s for target-absent and \~2.6s for target-present) were overall shorter compared to those in Toffolo et al. (2013) (\~5.5 for target-absent and \~3.5s for target-present). We therefore considered the possibility that the task used in Experiment 1 may have been less challenging and potentially insufficient to elicit doubt and trigger checking behavior. To test this, Experiment 2 employed the original stimuli from Toffolo et al. (2013). The preregistered analysis plan can be accessed at the following link: <https://github.com/Noamsarna/ocd_visual_search/tree/main/experiments/Experiment2>. In Experiment 2, we conducted a further power analysis mirroring the methods of Toffolo et al. (2013), utilizing their data and adopting a bootstrap approach to determine an adequately powered sample size, as detailed in the preregistration document for Experiment 2. We employed the Mersenne Twister pseudorandom number generator to ensure that our preregistration preceded data collection (Mazor et al., 2019).

```{r Exp2_load_data, warning=FALSE, cache=TRUE, include=FALSE}

# Pre processing  ---------------------------------------------------------
#load df from jatos 
exp2.jatos_df <-read_csv("../data/Exp_2_anon_jatos_results.csv")

failed_practice <- exp2.jatos_df %>% 
  filter(trial_index != "trial_index") %>%
  group_by(subj_id) %>% 
  summarise(max_trail = max(as.double(trial_index, na.rm = T)),
            failed_practice = max_trail <= 42) %>% 
  dplyr::select(subj_id, max_trail,failed_practice)  

exp2.jatos_df <- left_join(exp2.jatos_df, failed_practice)

#remove participants who failed practice 
 failed_practice$subj_id <- as.factor(failed_practice$subj_id)
 exp2.jatos_df<- exp2.jatos_df %>% filter(failed_practice=='FALSE') 

n_failed_practice <- failed_practice %>% pull(failed_practice) %>% sum()

total_valid_n <- exp2.jatos_df %>%
  filter(failed_practice=='FALSE') %>%
  pull(subj_id) %>%  n_distinct()

#load prolific df 
exp2.demo_prolific<-read.csv("../data/Ex2_anon_demo_prolific.csv")
exp2.demo_prolific$subj_id <- as.factor(exp2.demo_prolific$subj_id)

#keep only participants who didn't failed practice 
exp2.demo_prolific <- exp2.demo_prolific %>% left_join(., failed_practice %>% dplyr::select(subj_id, failed_practice),
                                                       by='subj_id')

exp2.demo_prolific <- exp2.demo_prolific %>%  filter(failed_practice== FALSE)

#merge df
exp2.jatos_df$subj_id <- as.factor(exp2.jatos_df$subj_id)
exp2.jatos_df <- left_join(exp2.jatos_df, exp2.demo_prolific, by='subj_id')

#parse oci data from df 
exp2.OCI_df <- exp2.jatos_df %>%
  filter(grepl('oci', Identifier)) %>% 
  dplyr::select(subj_id, question, answer_oci) %>% 
  mutate(attention_check = question %in% c("OCI-Attention_check_1","OCI-Attention_check_2")) %>%
  arrange(subj_id, question)%>%
  #arrange it in a long format df 
  group_by(subj_id) %>%
  summarise(oci_overall=sum(as.numeric(answer_oci[!attention_check])), #compute oci general score 
            failed_attention_OCI = answer_oci[question=='OCI-Attention_check_1']!=0 | #attention check failure
              answer_oci[question=='OCI-Attention_check_2']!=2,
            OCI_Absent = answer_oci[question=='OCI-Absent']) %>%
  mutate(
    #split to quartiles based on toffolo 2013 scores 
    OCI_quantile = case_when(oci_overall>=17 ~ "high", 
                             oci_overall<=5 ~ "low",
                             TRUE ~ 'else'))

#count how many participants in each group 
exp2.OCI_df %>% group_by(OCI_quantile) %>% count()

# merge data with OCI 
exp2.jatos_df <- left_join(exp2.jatos_df, 
                      exp2.OCI_df %>% dplyr::select(subj_id, oci_overall, OCI_quantile, OCI_Absent),
                      by='subj_id')

# create a df for the checking task ---------------------------------------

exp2.checking_task <- exp2.jatos_df %>% 
  filter(trial_type == "image-keyboard-response") %>%
  filter(isPractice=='FALSE') %>% 
  dplyr::select(trial_type,trial_index,subj_id,condition,
         rt,correct, isPractice, OCI_quantile, oci_overall, OCI_Absent)

#create a table making sure every participant have 50 trials, 25 absent and 25 present 
checking_table <-exp2.checking_task %>% group_by(subj_id) %>% 
  count(condition)

#recode variable
exp2.checking_task$rt <-as.numeric(exp2.checking_task$rt)

# accuracy df  -----------------------------------------------------------
exp2.checking_task$correct <- exp2.checking_task$correct=='TRUE' #change to Boolean 

exp2.checking_task <- exp2.checking_task %>% group_by(subj_id) %>% 
  mutate(mean_acc = mean(correct)) #calculate mean accuracy per subject 

#create accuracy df with acc score and OCI group per subject 
exp2.acc_df <- exp2.checking_task %>% 
  group_by(subj_id) %>% dplyr::select(subj_id, mean_acc, OCI_quantile) %>% slice(1)

#Create variables of accuracy in standard deviation units to exclude participants 
exp2.acc_df$Zscore <-scale(exp2.acc_df$mean_acc)[,1]

#mark participant who had error greater than Z>-2.5
exp2.acc_df$remove <-exp2.acc_df$Zscore<(-2.5)

exp2.acc_desc<-
exp2.acc_df %>% 
  filter(remove==F) %>% 
  group_by(OCI_quantile) %>% 
  summarise(mean_acc=mean(mean_acc))

exp2.acc_t_test<-
exp2.acc_df %>% 
  filter(remove==F) %>% 
  filter(OCI_quantile=='high' | OCI_quantile=='low') %>% 
t.test(mean_acc~OCI_quantile, data=., alternative="two.sided")


#merge acc df with the checking df 
exp2.checking_task <- left_join(exp2.checking_task, exp2.acc_df)

#remove participants who had more than Z>-2.5 errors. Three participants are removed. 
exp2.checking_task <-exp2.checking_task %>%
  filter(remove=='FALSE')

 checking_by_sub <- exp2.checking_task %>% 
  filter(OCI_quantile!='else') %>% 
  group_by(subj_id, condition, OCI_quantile,
           oci_overall) %>%
  summarise(N = n(),
            mean_RT = mean(rt, na.rm = T),
            median_RT = median(rt, na.rm = T),
            sd_RT = sd(rt, na.rm = T)) %>% ungroup() %>%
  mutate(log_mRT = log(mean_RT)) %>% 
  mutate(oci_type = ifelse(.$OCI_quantile == 'high', "High OC (OC+)", "Low OC (OC-)")) %>% 
  mutate(target_present = ifelse(.$condition=='ABS', "Absent", "Present"))

#test re-test OCI-R

OCI_R_exp1_exp2_cor_anon<- read_csv('../data/OCI_R_exp1_exp2_cor_anon.csv')
 
oci_r_correlation <- 
  cor.test(OCI_R_exp1_exp2_cor_anon$oci_total_exp1, 
                   OCI_R_exp1_exp2_cor_anon$oci_total_exp2, 
                   method = "pearson")
```

## Method

# Participants

Two hundred twenty-six participants were recruited via Prolific. To maximize statistical power for a group comparison, we invited former participants whose OCI-R scores were in the top or bottom quartile in Exp. 1. In line with our preregistered stopping rule, we kept data collection until we had invited all participants in the first and fourth quartiles from our previous experiment (n=220; n=213, respectively). Participants completed the OCI-R questionnaire again in the present study (the test-retest reliability for the OCI-R yielded a Pearson's correlation coefficient of `r apa_print(oci_r_correlation)$full_result`), and were assigned to the OC+/OC- groups based on the original cut-off scores from Toffolo et al., 2013 (OCI-R total score ≥ 17 for the OC+ group; OCI-R total score ≤ 5 for the OC- group). Our final sample consisted of 110 OC+ participants and 68 OC- participants. The entire experiment took 12 minutes to complete, and participants were paid £1.8 for their participation, equivalent to an hourly wage of £9.

## Procedure

A static version of Experiment 2 can be accessed here: <https://noamsarna.github.io/ocd_visual_search/experiments/demos/exp2/> Experiment 2 was similar to Experiment 1 with the following exceptions. First, we used the original stimuli from Toffolo et al. (2013). The visual search task consisted of one block of 50 individual search displays, each containing 25 elements. The search task was more challenging due to a larger search grid, which meant larger distances between stimuli, as well as reduced stimulus size. Second, Experiment 2 did not include an assessment of perceived difficulty, comprising only the visual search followed by the same questionnaires as in Experiment 1. Third, to make it identical to Toffolo et al. (2013), practice trials in Experiment 2 (four per block) involved the same stimuli as the main blocks. Fourth, participants were instructed to press the spacebar to move from the fixation cross screen to the search display screen, at which point the search display appeared immediately. Finally, the visual search part of the experiment included only the hard search type: detecting a closed square among open squares.

## Data Analysis

*Exclusion Criteria*

Since Experiment 2 served as a direct replication, we adopted the same rejection criteria as Toffolo et al. (2013), so that participants were excluded if their error count exceeded 2.5 standard deviations from the mean error rate of the entire sample. As in Experiment 1, participants were also excluded from the analysis if they failed to answer correctly one or more attention-check questions.

```{r Exp2_analyze_data, warning=FALSE, cache=TRUE, include=FALSE}

#plot figure of mean RT for each group  
exp_2_results<-
checking_by_sub %>% 
dplyr::select(subj_id, target_present, oci_type, mean_RT)  %>%
  ggplot(aes(x = target_present, y = mean_RT,  group = oci_type, shape = oci_type)) +
  stat_summary(fun = mean,
               geom = "point",
               position = position_dodge(0.9),
               size = 5) +
  stat_summary(fun.data = mean_se,
               geom = "errorbar",
               width = 0.4,
               position = position_dodge(0.9)) +
  # stat_summary(fun = mean,
  #              geom = "line",
  #              position = position_dodge(0.9)) +
  scale_shape_manual(values = c("High OC (OC+)" = 1, "Low OC (OC-)" = 2)) +
  scale_x_discrete(labels = c("FALSE" = "Absent", "TRUE" = "Present")) +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        text = element_text(size = 12)) +
  ylab('Mean RT (ms)')+
  labs(shape = "OC group")+ 
  coord_cartesian(ylim = c(2500,7500))

#ggsave(filename = "exp_2_results.png",width = 4, height = 3, dpi = 1500)  

# make a planned contrast df in which every participant has one row with a difference score of the mean 
#target absent search time minus the mean target present search time. 

planned_df <- exp2.checking_task %>% 
  filter(rt!='null') %>%   filter(OCI_quantile!='else') %>% 
  group_by(subj_id, condition, OCI_quantile, oci_overall) %>% 
  summarise(mean_RT =mean(rt))%>% ungroup

#long to wide format 
planned_wide <- spread(planned_df, key = condition, value = mean_RT)

#adding difference score 
planned_wide <- planned_wide %>% mutate(RT_diff = ABS- PRE) 
#mean for target present trials - 
round(mean(unlist(planned_df[planned_df$condition=='PRE', 'mean_RT'])), 2)

#mean for target absent trials -
round(mean(unlist(planned_df[planned_df$condition=='ABS', 'mean_RT'])), 2)


Exp2_H1_desc <-planned_df %>% group_by(condition) %>% summarise(mean_rt=mean(mean_RT),
                                                                sd=sd(mean_RT))

#number of errors per participants 
#mark trials of missing rt data 
exp2.checking_task$missing_rt <- exp2.checking_task$rt %>% is.na()

exp2.checking_task <-exp2.checking_task %>% 
  group_by(subj_id) %>% 
  mutate(num_error=50-(sum(correct))) 


exp_2_mean_error_rate <- round(mean(exp2.checking_task$num_error), 2) 
exp_2_SD_error <- round(sd(exp2.checking_task$num_error), 2)

# Bayesien analysis exp2 --------------------------------------------------
bayes_t_test_exp2 <-
  ttestBF(formula =RT_diff~OCI_quantile, data=planned_wide, rscale = 0.4, nullInterval = c(-Inf,0))

#cohen's D
exp2_H1_cohenD <-
planned_wide %>% cohens_d(RT_diff~OCI_quantile, var.equal = TRUE)

```

# Results

*Direct replication*

In contrast to Toffolo et al. (2013), where presence-absence differences in reaction time were more pronounced among OC+ participants, in our replication sample the one-tailed t-test of the interaction contrast (using the difference in search times as a DV), was not significant, `r apa_print(t.test(RT_diff~OCI_quantile, data=planned_wide, alternative="greater"))$statistic`, Cohen's *d*=`r print_num(exp2_H1_cohenD$effsize)` providing no evidence for the expected interaction. Notably, the numeric trend of the interaction in our sample was driven by shorter RT in the OC+ as compared to the OC- in target-present trials, rather than by longer RT for target-absent responses (Figure 2, Exp2). This pattern is different from that reported by Toffolo et al. (2013), where OC+ participants were slower in both search types, but particularly in target-absent searches (Figure 2, Toffolo et al., 2013). Unlike in Experiment 1, we observed no differences in accuracy between the groups (OC+: *M*=`r print_num(exp2.acc_desc$mean_acc[exp2.acc_desc$OCI_quantile=='high'])`, OC-: *M*=`r print_num(exp2.acc_desc$mean_acc[exp2.acc_desc$OCI_quantile=='low'])`; `r apa_print(exp2.acc_t_test)$statistic`). Finally, a one-sided Bayesian independent samples t-test produced a Bayes Factor of `r apa_print(bayes_t_test_exp2,scientific_threshold = c(min = 1e-10, max = 1e10))$statistic$interval`, providing moderate evidence for the null hypothesis of no group differences.

```{r figure_2, fig.cap="Figure 2 - Results from Experiment 1, Experiment 2 and Toffolo et al., 2013, 2014. Mean reaction times for target-absent and target-present trials (X-axis). Error bars represent the standard error of the mean. Shapes represent the OC groups: Circle for OC+; Triangle for OC-."}
knitr::include_graphics("figures/figure_2.png")
```

# Discussion

In two preregistered, large-sample studies, we found no evidence of prolonged search time among OC+ participants in target-absent trials, contrary to previous findings by Toffolo and colleagues (2013, 2014, 2016).

The most notable difference between our experiments and those conducted by Toffolo and colleagues (2013, 2014, 2016) lies in our use of an online setting versus their use of in-person lab experiments. Completing tasks online as opposed to a laboratory setting generates more "technical noise", that is, unexplained variance driven by technical variation. However, previous studies suggest that such noise has minimal impact on RT differences in perceptual tasks. In a study comparing RT distributions from a lab-based Matlab and an online JavaScript experiment, the results revealed near-identical RTs between the two setups [@deleeuwPsychophysics2016]. The JavaScript experiment showed a consistent delay of around 25 milliseconds, which had minimal impact on the sensitivity to RT changes due to experimental manipulations.

Furthermore, in our study, participants completed the visual search task using a range of computers and displays, rather than in a controlled lab environment with a fixed screen as in Toffolo et al. (2013, 2014, 2016). Yet, simulation studies have demonstrated minimal impact of technical variance on statistical power and the precision of effect size estimates [@brand2012]. Key behavioral findings in psychology, including those observed in the Stroop and flanker tasks, as well as effects reliant on much smaller time constants, like attentional blink and subliminal priming, have been successfully replicated in web-based studies [@crump2013]. Specifically, a recent online visual search study reported significant RT variations between experimental conditions, with a focus on smaller time constants than those anticipated in our paradigm [@mazorEfficientSearch2022]. Particularly strong evidence for the comparability of lab-based vs. web-based findings comes from a study which utilized a fully randomized design for reaction time effects [@hilbig2016]. The results showed that a word frequency effect (manifested in different RT) was comparable in magnitude across all three conditions. Taken together, these studies show that whereas some variations between settings in RT exist, they are minor, especially when the outcome measure is RT alterations due to experimental manipulations.

Additional differences between our research and Toffolo's studies, which could interact with OCD tendencies, are anonymity and demographic variations. It is plausible that the anonymity afforded by online studies could lead to participants feeling less responsible for study outcomes than identifiable psychology students who meet experimenters in person. Moreover, participants in Toffolo's studies were monitored by an eye-tracker camera, a factor that has been suggested to reduce reliance on internal cues such as metacognitive experiences [@noahWhenBothOriginal2018]. Given the sensitivity of OC+ individuals to personal responsibility [@salkovskis1985], and the heightened sense of anonymity in online studies, the transition to an online setting may have attenuated group differences in checking behavior.

Our failure to find an association between obsessive-compulsive tendencies and inference about absence may appear inconsistent with well-known clinical manifestations of OCD, such as those observed in "Hit-and-Run OCD". However, our experimental operationalization of inference about absence differed from these clinical manifestations in two important ways. First, we did not manipulate perceived responsibility, a key feature of "Hit-and-Run OCD" and one that is posited to play a key role in OCD more generally [@salkovskis1985]. Second, in the clinical example of "Hit-and-Run OCD", the compulsion is associated more with a recollection of an event rather than its direct experience. Indeed, most findings related to reduced confidence in individuals with OCD have been observed in relation to memory rather than perception (for review see @dar2022. More research is needed to elucidate the interaction of these two features with inference about absence in OCD.

Finally, this replication attempt puts into action several key features of replicable science [@tackett2017]. Our study included detailed preregistration with hypotheses, power analysis, analysis plan and exclusion criteria. We used the preregistration time-locking tool [@mazorNovelToolTimelocking2019], thereby guaranteeing that our registration preceded the data collection process. Furthermore, our study represents the first independent replication attempt. Lastly, we have made our raw data, analysis scripts, and task codes publicly available. Beyond a contribution to the experimental literature on OCD, we hope this report may serve as a helpful reference for reproducible and open clinical psychological science.

## Conclusion

The presented findings diverge from those of previous studies by Toffolo and her colleagues (2013, 2014, 2016), as we were unable to replicate the effect of prolonged search time for OC+ participants in target-absent trials. To the very least, this replication failure indicates that the original effect may be constrained to a specific setting, thus limiting its generalizability to other contexts. More broadly, our results advocate for the application of open science practices in clinical psychology research, to foster methodological integrity and ensure the reliability of findings.

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::

---
appendix: "appendix.Rmd"
---

\newpage

# (APPENDIX) Appendix {.unnumbered}

```{r child = "appendix.rmd"}
```
